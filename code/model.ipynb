{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aSK8suIfEEhB"
      },
      "source": [
        "# Práctica 1. Aprendizaje Automático\n",
        "\n",
        "Authors: Carlos Iborra Llopis (100451170), Alejandra Galán Arrospide (100451273) <br>\n",
        "For additional notes and requirements: https://github.com/carlosiborra/Grupo02-Practica2-AprendizajeAutomatico\n",
        "\n",
        "**❗If you are willing to run the code yourself, please clone the full GitHub repository, as it contains the necessary folder structures to export images and results❗**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLEt-dvtEEhD"
      },
      "source": [
        "# 0. Table of contents\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxxsnXoKEEhE"
      },
      "source": [
        "---\n",
        "# 1. Requirements\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-sQlMKfnEEhE"
      },
      "outputs": [],
      "source": [
        "\"\"\" Importing necessary libraries \"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import missingno as msno\n",
        "import seaborn as sns\n",
        "import scipy.stats as st\n",
        "import scipy\n",
        "import sklearn\n",
        "\n",
        "from matplotlib.cbook import boxplot_stats as bps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfcpG8-cEEhF"
      },
      "source": [
        "### 1.1. Cleaning ../data/img/ folder\n",
        "This way we avoid creating multiple images and sending the old ones to the trash.<br>\n",
        "Also using this to upload cleaner commits to GitHub.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5aTE7AdEEhF"
      },
      "outputs": [],
      "source": [
        "\"\"\" Cleaning the ../data/img/ folder \"\"\"\n",
        "import os\n",
        "import glob\n",
        "\n",
        "files = glob.glob(\"../data/img/*\")\n",
        "for f in files:\n",
        "    if os.path.isfile(f) and f.endswith(\".png\"):\n",
        "        os.remove(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dHr1HH49EEhF"
      },
      "source": [
        "---\n",
        "# 2. Reading the datasets\n",
        "Reading the datasets from the bz2 files, group 2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "A5rcyiSVEEhF",
        "outputId": "807c9649-7088-41a6-d1b7-04ae201faa86"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "with open('../data/attrition_available_2.pkl', 'rb') as pkl_file:\n",
        "    datos = pickle.load(pkl_file)\n",
        "\n",
        "datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EVkHvy4-EEhG"
      },
      "outputs": [],
      "source": [
        "# Export the data to a csv file\n",
        "datos.to_csv('../data/attrition_available_2.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmz3FvAJEEhG"
      },
      "source": [
        "---\n",
        "# 3. EDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBDRk1fEEEhG"
      },
      "source": [
        "<mark>(0,15 puntos) Hacer un EDA muy simplificado: cuántas instancias / cuantos \n",
        "atributos y de qué tipo (numéricos, ordinales, categóricos); columnas constantes o \n",
        "innecesarias; que proporción de missing values por atributo; tipo de problema: \n",
        "(clasificación o regresión); ¿es desbalanceado?</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6MI7qqdEEhG"
      },
      "source": [
        "**Key Concepts of Exploratory Data Analysis**\n",
        "\n",
        "- **2 types of Data Analysis**\n",
        "  - Confirmatory Data Analysis\n",
        "  - Exploratory Data Analysis\n",
        "- **4 Objectives of EDA**\n",
        "  - Discover Patterns\n",
        "  - Spot Anomalies\n",
        "  - Frame Hypothesis\n",
        "  - Check Assumptions\n",
        "- **2 methods for exploration**\n",
        "  - Univariate Analysis\n",
        "  - Bivariate Analysis\n",
        "- **Stuff done during EDA**\n",
        "  - Trends\n",
        "  - Distribution\n",
        "  - Mean\n",
        "  - Median\n",
        "  - Outlier\n",
        "  - Spread measurement (SD)\n",
        "  - Correlations\n",
        "  - Hypothesis testing\n",
        "  - Visual Exploration\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10RH0juOEEhH"
      },
      "source": [
        "## 3.0. Dataset preparation\n",
        "\n",
        "To conduct exploratory data analysis (EDA) on our real data, we need to prepare the data first. Therefore, we have decided to separate the data into training and test sets at an early stage to avoid data leakage, which could result in an overly optimistic evaluation of the model, among other consequences. This separation will be done by dividing the data prematurely into training and test sets since potential data leakage can occur from the usage of the test partition, especially when including the result variable.\n",
        "\n",
        "It is important to note that this step is necessary because all the information obtained in this section will be used to make decisions such as dimensionality reduction. Furthermore, this approach makes the evaluation more realistic and rigorous since the test set is not used until the end of the process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCXvrbWOEEhH"
      },
      "source": [
        "### 3.0.1. Stratified K-Fold\n",
        "To ensure a fair and unbiased evaluation of our model's performance, we will be using stratified k-fold for dividing our data into training and test sets. Stratified k-fold is a commonly used technique in machine learning that ensures that the distribution of classes in the training and test sets is similar, thus reducing the risk of introducing bias into our model's performance evaluation.\n",
        "\n",
        "By using stratified k-fold, we can ensure that each fold of the data used for training and testing our model contains a representative sample of all the classes in the dataset. This helps to account for any potential class imbalance in the data, ensuring that our model is trained and tested on a diverse set of data, leading to a more reliable evaluation of its performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyLpG_6xEEhH"
      },
      "source": [
        "Note: as we are second group, we will be using 2 as our random state seed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NBCf63I7EEhH"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etmEyffrEEhI"
      },
      "outputs": [],
      "source": [
        "\"\"\" Train Test Split using Stratified K-Fold \"\"\"\n",
        "\n",
        "# Make a copy of the data (we will re-split the data later to ensure that the data is not contaminated)\n",
        "datos_copy = datos.copy()\n",
        "\n",
        "# Define the number of folds for stratified k-fold\n",
        "n_splits = 5\n",
        "\n",
        "# Initialize the StratifiedKFold object\n",
        "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Iterate over the stratified k-fold splits\n",
        "for train_index, test_index in stratified_kfold.split(datos_copy, datos_copy['Attrition']):\n",
        "    # Split the data into training and test sets using the current split indices\n",
        "    train_set = datos_copy.iloc[train_index]\n",
        "    test_set = datos_copy.iloc[test_index]\n",
        "    \n",
        "    # Extract the features (X) and target (y) from the training and test sets\n",
        "    X_train = train_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
        "    y_train = train_set['Attrition']  # Extract the 'Attrition' column as the target\n",
        "    \n",
        "    X_test = test_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
        "    y_test = test_set['Attrition']  # Extract the 'Attrition' column as the target\n",
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vCa2jTAtEEhI"
      },
      "source": [
        "Check the train-test division correctness"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJlx46q1EEhI",
        "outputId": "18354307-4290-4913-d29f-ec36770d7c2d"
      },
      "outputs": [],
      "source": [
        "# Show the head of X_train, y_train, X_test, y_test\n",
        "print(\"--------------------\\n\")\n",
        "print(f\"{X_train.head(1)}\", f\"{y_train.head(1)}\", f\"{X_test.head(1)}\", f\"{y_test.head(1)}\", sep=\"\\n--------------------\\n\")\n",
        "print(\"--------------------\\n\")\n",
        "\n",
        "print(f\"{X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Check is division summatory is correct\n",
        "if X_train.shape[0] + X_test.shape[0] == datos_copy.shape[0]:\n",
        "    print(\n",
        "        f\"\\nThe train test division is correct: {X_train.shape[0]} + {X_test.shape[0]} = {datos_copy.shape[0]}\"\n",
        "    )\n",
        "else:\n",
        "    print(\"\\nERROR: The train test division is incorrect\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2CHzF5TEEhI",
        "outputId": "1f02c104-45a2-4f0e-ba0c-0a9b2620ee53"
      },
      "outputs": [],
      "source": [
        "# Check the train-test division correctness by comparing the class distribution in the original dataset and the train and test sets.\n",
        "print(\"\\n--------------------\\n\")\n",
        "print(\"Original dataset class distribution:\\n\", datos_copy['Attrition'].value_counts(normalize=True))\n",
        "print(\"\\n--------------------\\n\")\n",
        "print(\"Train set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"\\n--------------------\\n\")\n",
        "print(\"Test set class distribution:\\n\", y_test.value_counts(normalize=True))\n",
        "print(\"\\n--------------------\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "lw3r1P3pEEhJ"
      },
      "source": [
        "As we can observe, the class distribution is almost perfectly preserved in both the training and test sets and that the sum of the number of rows in train and test give us the total amount of rows in the raw dataset. This is due to the fact that the stratified k-fold algorithm does not guarantee that the class distribution is exactly the same in each fold, but rather that it is similar.<br>\n",
        "Also, we can notice how the distribution of the classes is very similar in both the training and test sets, which is a good sign."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juatdhB6EEhJ"
      },
      "source": [
        "## 3.1. Dataset and problem description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aH6qqXBdEEhJ"
      },
      "source": [
        "The dataset we are given contains the following atributes information:\n",
        "\n",
        "0. **hrs**: The number of hours worked by the employee (float64)\n",
        "1. **absences**: The number of absences taken by the employee (float64)\n",
        "2. **JobInvolvement**: The level of involvement the employee has in their job (float64)\n",
        "3. **PerformanceRating**: The employee's performance rating (float64)\n",
        "4. **EnvironmentSatisfaction**: The level of satisfaction the employee has with their work environment (float64)\n",
        "5. **JobSatisfaction**: The level of satisfaction the employee has with their job (float64)\n",
        "6. **WorkLifeBalance**: The balance between work and personal life for the employee (float64)\n",
        "7. **Age**: The age of the employee (float64)\n",
        "8. **Attrition**: Whether the employee has left the company or not (object) -> **Target variable**\n",
        "9. **BusinessTravel**: The frequency of the employee's business travel (object)\n",
        "10. **Department**: The department the employee works in (object)\n",
        "11. **DistanceFromHome**: The distance from the employee's home to their workplace (float64)\n",
        "12. **Education**: The highest level of education attained by the employee (int64)\n",
        "13. **EducationField**: The field of study the employee specialized in (object)\n",
        "14. **EmployeeCount**: The number of employees in the company (float64)\n",
        "15. **EmployeeID**: A unique identifier for each employee (int64)\n",
        "16. **Gender**: The gender of the employee (object)\n",
        "17. **JobLevel**: The employee's job level in the company hierarchy (float64)\n",
        "18. **JobRole**: The specific role the employee has in their department (object)\n",
        "19. **MaritalStatus**: The employee's marital status (object)\n",
        "20. **MonthlyIncome**: The employee's monthly income (float64)\n",
        "21. **NumCompaniesWorked**: The number of companies the employee has worked for before joining the current company (float64)\n",
        "22. **Over18**: Whether the employee is over 18 years old (presumably all employees are) (object)\n",
        "23. **PercentSalaryHike**: The percentage of salary increase the employee received in their last salary hike (float64)\n",
        "24. **StandardHours**: The standard number of working hours in the company (float64)\n",
        "25. **StockOptionLevel**: The level of stock option the employee has (float64)\n",
        "26. **TotalWorkingYears**: The total number of years the employee has worked (float64)\n",
        "28. **TrainingTimesLastYear**: The number of times the employee received training in the last year (float64)\n",
        "29. **YearsAtCompany**: The number of years the employee has been with the company (float64)\n",
        "30. **YearsSinceLastPromotion**: The number of years since the employee's last promotion (float64)\n",
        "31. **YearsWithCurrManager**: The number of years the employee has been with their current manager (float64)\n",
        "\n",
        "**Note**: the values in between parenthesis correspond to the value type of each column in the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zagat4zwEEhK",
        "outputId": "11e31e04-80bc-45c9-919b-2686873df41b"
      },
      "outputs": [],
      "source": [
        "num_atributos  = len(datos.keys())\n",
        "print(\"We have\", num_atributos, \"attributes.\")\n",
        "num_instances = len(datos)\n",
        "print(\"We have\", num_instances, \"instances.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Suk6lu4EEhK",
        "outputId": "bc72ea0d-bb10-44a0-9593-02ff631a086e"
      },
      "outputs": [],
      "source": [
        "train_set.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UJ-w9nLEEhK"
      },
      "source": [
        "### 3.1.1. Dataset visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LG6bg20oEEhK",
        "outputId": "bd4fcfb3-3521-48b1-9ca1-c22560078e84"
      },
      "outputs": [],
      "source": [
        "\"\"\" Histogram for visualization of the numerical variables \"\"\"\n",
        "fig, ax = plt.subplots(figsize=(20, 14))\n",
        "train_set.hist(ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "LAhgS9TCJ5uR"
      },
      "source": [
        "Thanks to this visualization we can note several things. \n",
        "\n",
        "1. **Emproyee ID** appears to have the same amount of each number in its range. This is very logical taking into account that this attribute is an identifier. This attribute will be eliminated in the future. \n",
        "\n",
        "2. **Standard Hours** seems to have a unique value of 8. This attribute will need further analysis in order to consider its deletion. \n",
        "\n",
        "3. As Standard Hours, **Employee Count** seems to have a unique value of 1. This attribute will also need further analysis. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WMJnnd1JEEhK",
        "outputId": "c827d6ee-3273-4e98-fef2-203bc16050a3"
      },
      "outputs": [],
      "source": [
        "\"\"\" Pie series to plot and visualize for categorical variables \"\"\"\n",
        "fig, ax = plt.subplots(3, 3, figsize=(20, 15))\n",
        "for i, col in enumerate(train_set.select_dtypes(include='object')):\n",
        "    train_set[col].value_counts().plot.pie(ax=ax[i//3, i%3], autopct='%1.1f%%', fontsize=12, title=col)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "snyR1SnpLrLK"
      },
      "source": [
        "From this numerical visualization, we can also obtain relevant information.<br>\n",
        "1. The attribte **BusinessTravel** is an ordinal attribute. This means that the natual order of the values is important. In this case, the order is: **Non-Travel**, **Travel_Rarely**, **Travel_Frequently**. This attribute will be transformed in the future.\n",
        "   \n",
        "2. The attribute **'Over18'** has a constant value, which means it adds no value to the analysis. Therefore, it will be dropped in the further sections"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.2. Attribute type division"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we have seen, there are two types of attributes in the dataset: numerical and categorical. In this section, we will divide the attributes into these two types and analyze them separately.\n",
        "\n",
        "But that's not all. Categorical attributes are further divided into two types: ordinal (attributes that have a natural order) and nominal (attributes that do not have a natural order). Therefore, we will divide the categorical attributes into these two types and analyze them separately.\n",
        "\n",
        "**Note**: this is important as it prevents errors when treating and measuring data in the EDA. For example, we cannot calculate the mean of a categorical attribute, but we can calculate the mean of a numerical attribute."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2.1. Categorical and numerical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First of all, we divide our data-set into two general groups, categorical and numerical variables\n",
        "X_train_str = X_train.select_dtypes(include=object)\n",
        "X_train_num = X_train.select_dtypes(exclude=object)\n",
        "print(X_train_str.head(2))\n",
        "print(X_train_num.head(2))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2.2. Ordinal and nominal attributes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After dividing the dataset into categorical and numerical, we will divide the categorical ones into other two new subsets, ordinal and nominal. This will later allow us to apply different preprocessing techniques to each subset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next, we create a new subset of the ordinal variables\n",
        "X_train_ordinals = X_train[['BusinessTravel']]\n",
        "print(X_train_ordinals.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next, we take out the ordinal variables from the categorical variables group -> nominal group\n",
        "X_train_nominal = X_train_str.drop('BusinessTravel', axis=1)\n",
        "print(X_train_nominal.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We print the column names of each subset to check that the division was done correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the columns of the two new data-sets\n",
        "print(\"Numerical variables:\", list(X_train_num.columns))\n",
        "print(\"Categorical variables:\", list(X_train_str.columns))\n",
        "print(\"  - Ordinal variables:\", list(X_train_ordinals.columns))\n",
        "print(\"  - Nominal variables:\", list(X_train_nominal.columns))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3.3. Irrelevant and constant attributes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After dividing the dataset into three different subsets, we will drop the attributes that are irrelevant or constant in each subset. This will allow us to reduce the dimensionality of the dataset and make it easier to analyze."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.1. Elimination of irrelevant attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_num.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We take out the EmproyeeID column from the numerical variables group since its an identifier \n",
        "X_train_num = X_train_num.drop('EmployeeID', axis=1)\n",
        "X_train_num.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We look for variables with only one value, in order to take them out\n",
        "for i in X_train_nominal.columns:\n",
        "  print(X_train_str[i].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(X_train_num.columns)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3.2. Elimination of constant attributes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.3.2.1. Constant numerical attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We check if the assumptions about the constantness made in previous sections about the attributes 'StandardHours' and 'EmployeeCount' are correct."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print \"StandardHours\" distribution of values\n",
        "print(list(X_train_num['StandardHours'].unique()))\n",
        "print(X_train_num['StandardHours'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print \"EmployeeCount\" distribution of values\n",
        "print(list(X_train_num['EmployeeCount'].unique()))\n",
        "print(X_train_num['EmployeeCount'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As we can see, both the attributes we suspected have a constant value and are not useful for the analysis. We are going to conduct a quick overall analysis to ensure that we are not overlooking any other constant attributes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in X_train_num.columns: \n",
        "  unique_vals = list(X_train_num[i].unique())\n",
        "  print(i)\n",
        "  print(unique_vals)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We drop constant attributes in the numerical subset: 'StandardHours' and 'EmployeeCount'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_num = X_train_num.drop('StandardHours', axis=1 )\n",
        "X_train_num.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_num = X_train_num.drop('EmployeeCount', axis=1 )\n",
        "X_train_num.columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.3.2.2. Constant categorical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print \"Over18\" distribution of values\n",
        "print(list(X_train_nominal['Over18'].unique()))\n",
        "print(X_train_nominal['Over18'].value_counts())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As expected, Over18 only has only one value different than Nan, therefore, it does not provide any valuable information, so we drop it from the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_nominal = X_train_nominal.drop ('Over18', axis=1 )\n",
        "X_train_nominal.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We check all the subsets we will be using \n",
        "print(X_train_nominal.columns)\n",
        "print(X_train_num.columns)\n",
        "print(X_train_ordinals.columns)\n",
        "print(len(X_train_num.columns)+len(X_train_nominal.columns) + len(X_train_ordinals.columns))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As it can be noticed, we obtained 26 attributes, so we have reduced the dimensionality by 4 attributes (13.33%) with respect to the original dataset."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq3bB9WpEEhL",
        "notebookRunGroups": {
          "groupValue": ""
        }
      },
      "source": [
        "## 3.4. Missing values"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "g9FstM_QEEhL"
      },
      "source": [
        "We check the number the total number of missing values in the dataset in order to know if we have to clean the dataset or not.<br>Here we will be using the `train_set` partition (and not X_train nor y_train) as it contains both the target variable and the rest of the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fObDqiWmEEhL",
        "outputId": "4a4d40a9-ac6f-4c85-abc7-0423ef056984"
      },
      "outputs": [],
      "source": [
        "print(train_set.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 699
        },
        "id": "pTMOf94WEEhL",
        "outputId": "b9bbb67b-1175-40db-a8fc-1096f1a02166"
      },
      "outputs": [],
      "source": [
        "\"\"\" Plot in a barplot the percentage of missing values in each column \"\"\"\n",
        "import pylab\n",
        "\n",
        "data = [(col, train_set[col].isnull().sum() / len(train_set))\n",
        "        for col in train_set.columns if train_set[col].isnull().sum() > 0]\n",
        "col_names = ['column', 'percent_missing']\n",
        "missing_df = pd.DataFrame(data, columns=col_names).sort_values('percent_missing')\n",
        "pylab.rcParams['figure.figsize'] = (15, 8)\n",
        "missing_df.plot(kind='barh', x='column', y='percent_missing');\n",
        "plt.title('Percent of missing values in colummns');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zylEyYP6EEhL"
      },
      "source": [
        "### 3.2.1. Missing values visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 891
        },
        "id": "WWF5yu0-EEhL",
        "outputId": "8ebc5d37-6d8b-498a-f861-d9df114122b2"
      },
      "outputs": [],
      "source": [
        "\"\"\" Missing values bar plot \"\"\"\n",
        "msno.bar(train_set, figsize=(20, 8), fontsize=12, color='steelblue', labels=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        },
        "id": "W3nCFlVZEEhL",
        "outputId": "191d5bc2-3b18-46a4-d3ec-321301ad70c6"
      },
      "outputs": [],
      "source": [
        "\"\"\" Missing values matrix \"\"\"\n",
        "msno.matrix(train_set, figsize=(20, 8), fontsize=12, color=(0.42, 0.1, 0.05))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 839
        },
        "id": "29cVhGu7EEhM",
        "outputId": "8a73d834-841a-447e-f345-3f305ddd72c1"
      },
      "outputs": [],
      "source": [
        "\"\"\" Missing values dendrogram \"\"\"\n",
        "msno.dendrogram(train_set, figsize=(20, 8), fontsize=12, orientation='top')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNFbZT0EEEhM"
      },
      "source": [
        "### 3.2.2. Observations and conclusion\n",
        "\n",
        "- Many variables have a significant number of missing values, ranging from 588 to over 771 missing values, which means that having 4410 rows in the dataset, we have a significant number of missing values ranging from 13.3% to 17.5% of the total number of rows in the dataset, which is significant.\n",
        "  \n",
        "  These variables include: 'hrs', 'absences', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age', 'BusinessTravel', 'Department', 'DistanceFromHome', 'Education', 'EmployeeCount', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus', 'MonthlyIncome', 'NumCompaniesWorked', 'Over18', 'PercentSalaryHike', 'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', and 'YearsSinceLastPromotion'.\n",
        "\n",
        "- Some variables have no missing values, such as 'Attrition' (as it is the target variable), 'EducationField', and 'YearsWithCurrManager'.\n",
        "\n",
        "It's important to note that missing values can have an impact on the quality and reliability of the data and may require appropriate handling techniques, such as imputation or deletion, depending on the specific analysis or modeling objectives.\n",
        "\n",
        "Note that none of the attributes have a missing rate high enought for them to be eliminated because of it. Its possible to use imputation to solve this problem. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGEKL15LEEhM"
      },
      "source": [
        "## 3.3. Outliers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8Fu2zl9EEhM"
      },
      "source": [
        "Detecting outliers in a dataset before training a model is crucial because outliers can significantly affect the performance and accuracy of the model. Outliers are data points that deviate significantly from the rest of the dataset and can cause the model to learn incorrect patterns and relationships. When outliers are present in the data, they can also increase the variance of the model, which can result in overfitting. Overfitting occurs when the model fits too closely to the training data, leading to poor generalization to new data. Therefore, it is important to detect and handle outliers properly to ensure the model's accuracy and robustness."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0ETBlBndEEhM"
      },
      "source": [
        "**Note:** outliers are only useful when the attributes are not categorical, as they are not useful for classification problems. Therefore, only the numerical attributes (`X_train_num`) will be considered in this section ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQ9JmcrvEEhM"
      },
      "source": [
        "### 3.3.1. Outliers visualization"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "NAcMEzI2EEhM"
      },
      "source": [
        "#### 3.3.1.1. Boxplot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 830
        },
        "id": "xkmxh387EEhM",
        "outputId": "09c7db12-88e1-4839-bb9c-4f503002e6d0"
      },
      "outputs": [],
      "source": [
        "\"\"\" Box plot to detect outliers \"\"\"\n",
        "fig, ax = plt.subplots(figsize=(20, 10))\n",
        "sns.boxplot(data=X_train_num, orient='h', palette='Set2') # ,showfliers=False\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bdr08NlEEhM"
      },
      "source": [
        "#### 3.3.1.2. Histogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kkcbRHhIEEhM",
        "outputId": "5530b99b-15a0-487a-e2ae-18d4bb51ca56"
      },
      "outputs": [],
      "source": [
        "\"\"\" Histograms to detect outliers \"\"\"\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "X_train_num.hist(ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "igseDV1oEEhN"
      },
      "source": [
        "#### 3.3.1.3. Skewness and kurtosis\n",
        "Skewness and kurtosis are commonly used to measure the shape of a distribution. Skewness measures the degree of asymmetry in the distribution, while kurtosis measures the degree of flatness in the distribution compared to a normal distribution.<br>\n",
        "We will look for observations that are far from the central tendency of the distribution and may indicate the presence of extreme values or data points that do not fit the pattern of the majority of the data (which as expected, happens to be the case in this dataset)."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "JEdyXl8sEEhN"
      },
      "source": [
        "**Skewness**: measure of the asymmetry of the probability distribution of a real-valued random variable about its mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIdhzJ0-EEhN",
        "outputId": "c2a94892-0b9e-4c26-8f7a-ac79b301d598"
      },
      "outputs": [],
      "source": [
        "\"\"\" Skewness \"\"\"\n",
        "X_train_num.skew().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "AR1J7o0CEEhN",
        "outputId": "8aa0196f-25c0-45ee-ca8c-902ca0ce1baf"
      },
      "outputs": [],
      "source": [
        "sns.distplot(X_train_num.skew(), color=\"blue\", axlabel=\"Skewness\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "MnuLdn87EEhN"
      },
      "source": [
        "**Kurtosis**: measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SW0BqZrxEEhN",
        "outputId": "8f39e470-eebe-4114-8596-5f5fb197838a"
      },
      "outputs": [],
      "source": [
        "\"\"\" Kurtosis \"\"\"\n",
        "X_train_num.kurt().sort_values(ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 939
        },
        "id": "TOfid964EEhN",
        "outputId": "e2fefe1a-405f-4e44-c23e-b00e532355aa"
      },
      "outputs": [],
      "source": [
        "sns.distplot(X_train_num.kurt(), color=\"r\", axlabel=\"Kurtosis\", norm_hist=False, kde=True, rug=False)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr2WBIT3NI57"
      },
      "source": [
        "### 3.3.2. Importance of outliers on our models\n",
        "\n",
        "- **Logistic regression** aims to fit a linear boundary that separates the two classes in the dataset. When outliers are present, they can shift this boundary and lead to incorrect predictions. Additionally, outliers can affect the estimation of the regression coefficients and standard errors, leading to biased parameter estimates and incorrect hypothesis tests.\n",
        "\n",
        "- **Boosting** algorithms are sensitive to outliers in the training data, as they aim to fit the data as closely as possible. Outliers can have a significant impact on the model's performance and can lead to overfitting.<br>\n",
        "In boosting, each subsequent model in the sequence aims to correct the errors made by the previous model, focusing on the misclassified samples. Outliers are usually given high weights in the subsequent models to improve their performance on these samples. This can result in overfitting and poor generalization on new, unseen data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6l23U0sPEEhN"
      },
      "source": [
        "## 3.4. Correlation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RrgCQ7d7EEhO"
      },
      "source": [
        "In this section we are getting information about the correlation of the variables between them. This information is valuable in order to make good decisions when deleting redundant attributes.<br>Also note we are getting information about the correlation between each attribute and the target variable. This allows us to know the most relevant attributes, making the best decisions when creating the different models.\n",
        "\n",
        "As above, we will be using only the numerical attributes (`X_train_num`) in this section (if not, warnings will be shown). But, unfortunately, the target variable is not numerical, so some warnings will be shown."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tx6dl1tQEEhO",
        "outputId": "6d12f4bb-b698-45b2-b212-65dc73f36507"
      },
      "outputs": [],
      "source": [
        "\"\"\" Correlation \"\"\"\n",
        "correlation = abs(X_train_num.corr())\n",
        "print(correlation.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X3SDZn1xEEhO",
        "outputId": "4f6e5994-e6f0-4b91-c44f-53a9efb386ce"
      },
      "outputs": [],
      "source": [
        "\"\"\" Correlation for both numerical and categorical variables - target variable\"\"\"\n",
        "# Correlation with the target variable\n",
        "from pandas import factorize\n",
        "\n",
        "# Note, we use the target variable just to see the correlation with it - not for the rest of the correlation tests\n",
        "\n",
        "labels, uniques = factorize(train_set['Attrition'])\n",
        "train_set['Attrition'] = labels\n",
        "abs(train_set.corr()['Attrition']).sort_values(ascending=False)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZTQS_XKEEhO"
      },
      "source": [
        "### 3.4.0. Obtaining the correlation matrix formatted into our own data structure\n",
        "This is done for the sake of simplicity and to be able to visualize the correlation matrix in a more intuitive way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98PNe1UPEEhO",
        "outputId": "d1346adf-bddc-4953-f831-acfe145d4f28"
      },
      "outputs": [],
      "source": [
        "correlation_dict = {}\n",
        "\n",
        "# Export the data as a list of lists\n",
        "list_correlation = X_train_num.values.tolist()\n",
        "\n",
        "\n",
        "# Now lets insert the each list as the value of a dictionary with the column name as the key\n",
        "for i, col in enumerate(X_train_num.columns):\n",
        "    correlation_dict[col] = list_correlation[i]\n",
        "    \n",
        "# Plotting the dictionary column by column sepparated by \\n\n",
        "print( \"\\n\\n\".join(\"{}\\t{}\".format(k, v) for k, v in correlation_dict.items()) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BajQthkZEEhO"
      },
      "source": [
        "### 3.4.1. Correlation visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2bcfzGapEEhO"
      },
      "source": [
        "#### 3.4.1.1. Correlation heatmap"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "P8d3VmNhEEhO",
        "outputId": "345a8ba4-f6e6-4e52-af38-bfd704f6b007"
      },
      "outputs": [],
      "source": [
        "\"\"\" Seaborn correlation heatmap \"\"\"\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(20, 20))\n",
        "\n",
        "plt.title(\"Correlation Heatmap\", fontsize=20)\n",
        "sns.heatmap(\n",
        "    correlation,\n",
        "    square=True,\n",
        "    annot=True,\n",
        "    cmap=\"coolwarm\",\n",
        "    fmt=\".2f\",\n",
        "    linewidths=0.5,\n",
        "    ax=ax,\n",
        "    cbar_kws={\"shrink\": 0.8},\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upon analyzing the correlation matrix of the dataset, we observe that most of the attributes are not correlated with each other, indicating that they contain unique information. However, there are a few attributes that exhibit a relatively high correlation, which we will investigate further.\n",
        "\n",
        "- First, we note that `YearsAtCompany` and `YearsWithCurrManager` have a correlation coefficient of 0.78, which is considered a strong positive correlation. This implies that the longer an employee has been with the company, the longer they have likely been with their current manager.\n",
        "- Similarly, `PercentSalaryHike` and `PerformanceRating` have a correlation coefficient of 0.77, indicating that employees who receive a higher salary hike are also more likely to receive a higher performance rating.\n",
        "- `Age` and `TotalWorkingYears` are also relatively strongly correlated, with a correlation coefficient of 0.61, suggesting that older employees tend to have more years of working experience.\n",
        "- Lastly, `TotalWorkingYears` and `YearsAtCompany` have a correlation coefficient of 0.61, indicating that employees who have worked longer in general are also likely to have spent more time with the company.\n",
        "\n",
        "Despite these relatively high correlation coefficients, we choose not to delete any of these attributes. The are two **reasons** for this decission.\n",
        "<br>**Firstly**, the correlation values are not high enough to suggest a strong linear relationship between the attributes, indicating that they may still contain unique information.\n",
        "<br>**Secondly**, due to the small size of the dataset we are dealing with, the potential gain in performance from attribute deletion may not be significant compared to the loss of valuable information caused by their removal.\n",
        "<br>Therefore, we will retain all the attributes in our analysis.\n",
        "\n",
        "It's important to note that while correlation can provide useful insights, it does not necessarily imply causation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjWaZXVPEEhQ"
      },
      "source": [
        "---\n",
        "# 4. Train-Test division \n",
        "\n",
        "\n",
        "**Note**: This division was already done before in *3.0. Dataset preparation*. We overwrite it to start from a clean state so there are no possible data contamination derived from the EDA process. Thus, no further explaination is needed.\n",
        "\n",
        "<mark>En esta práctica la evaluación será más sencilla que en la primera. Simplemente \n",
        "dividiremos los datos en un conjunto de train para entrenar y ajustar hiper-\n",
        "parámetros, y un conjunto de test en el que evaluaremos las distintas posibilidades \n",
        "que se probarán en la práctica. Hay que recordar que En problemas de clasificación \n",
        "desbalanceados hay que usar particiones estratificadas y métricas adecuadas \n",
        "(balanced_accuracy, f1, matriz de confusión). También es conveniente que los \n",
        "métodos de construcción de modelos traten el desbalanceo, usando por ejemplo \n",
        "el parámetro class_weight=”balanced”.</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HbMsxfaYEEhQ"
      },
      "source": [
        "## 4.1. Stratified K-Fold Train-Test split\n",
        "To ensure a fair and unbiased evaluation of our model's performance, we will be using stratified k-fold for dividing our data into training and test sets. Stratified k-fold is a commonly used technique in machine learning that ensures that the distribution of classes in the training and test sets is similar, thus reducing the risk of introducing bias into our model's performance evaluation.\n",
        "\n",
        "By using stratified k-fold, we can ensure that each fold of the data used for training and testing our model contains a representative sample of all the classes in the dataset. This helps to account for any potential class imbalance in the data, ensuring that our model is trained and tested on a diverse set of data, leading to a more reliable evaluation of its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMUgfC65EEhQ"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries\n",
        "from sklearn.model_selection import StratifiedKFold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U3q0OFrQEEhQ"
      },
      "outputs": [],
      "source": [
        "\"\"\" Train Test Split using Stratified K-Fold \"\"\"\n",
        "\n",
        "# Make a copy of the data (we will re-split the data later to ensure that the data is not contaminated)\n",
        "datos_copy = datos.copy()\n",
        "\n",
        "# Define the number of folds for stratified k-fold\n",
        "n_splits = 5\n",
        "\n",
        "# Initialize the StratifiedKFold object\n",
        "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
        "\n",
        "# Iterate over the stratified k-fold splits\n",
        "for train_index, test_index in stratified_kfold.split(datos_copy, datos_copy['Attrition']):\n",
        "    # Split the data into training and test sets using the current split indices\n",
        "    train_set = datos_copy.iloc[train_index]\n",
        "    test_set = datos_copy.iloc[test_index]\n",
        "    \n",
        "    # Extract the features (X) and target (y) from the training and test sets\n",
        "    X_train = train_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
        "    y_train = train_set['Attrition']  # Extract the 'Attrition' column as the target\n",
        "    \n",
        "    X_test = test_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
        "    y_test = test_set['Attrition']  # Extract the 'Attrition' column as the target\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOUv0w2TEEhQ",
        "outputId": "661f65a0-b2d3-4705-fc36-9fbe15fda99d"
      },
      "outputs": [],
      "source": [
        "print(f\"{X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}\")\n",
        "\n",
        "# Check is division summatory is correct\n",
        "if X_train.shape[0] + X_test.shape[0] == datos_copy.shape[0]:\n",
        "    print(\n",
        "        f\"\\nThe train test division is correct: {X_train.shape[0]} + {X_test.shape[0]} = {datos_copy.shape[0]}\"\n",
        "    )\n",
        "else:\n",
        "    print(\"\\nERROR: The train test division is incorrect\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-yfAdnsQEEhR",
        "outputId": "ab350b55-a1cc-401e-dbf6-0949801bfd50"
      },
      "outputs": [],
      "source": [
        "# Check the train-test division correctness by comparing the class distribution in the original dataset and the train and test sets.\n",
        "print(\"\\n--------------------\\n\")\n",
        "print(\"Original dataset class distribution:\\n\", datos_copy['Attrition'].value_counts(normalize=True))\n",
        "print(\"\\n--------------------\\n\")\n",
        "print(\"Train set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
        "print(\"\\n--------------------\\n\")\n",
        "print(\"Test set class distribution:\\n\", y_test.value_counts(normalize=True))\n",
        "print(\"\\n--------------------\\n\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2. Dataset type subsets and cleaning"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we have already done the following steps before, so no further explaination is needed."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.1. Attribute subsets"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.2.1.1. Categorical and numerical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# First of all, we divide our data-set into two general groups, categorical and numerical variables\n",
        "X_train_str = X_train.select_dtypes(include=object)\n",
        "X_train_num = X_train.select_dtypes(exclude=object)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.2.1.1. Ordinal and nominal attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next, we create a new subset of the ordinal variables\n",
        "X_train_ordinals = X_train[['BusinessTravel']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Next, we take out the ordinal variables from the categorical variables group -> nominal group\n",
        "X_train_nominal = X_train_str.drop('BusinessTravel', axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We print the column names of each subset to check that the division was done correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print the columns of the two new data-sets\n",
        "print(\"Numerical variables:\", list(X_train_num.columns))\n",
        "print(\"Categorical variables:\", list(X_train_str.columns))\n",
        "print(\"  - Ordinal variables:\", list(X_train_ordinals.columns))\n",
        "print(\"  - Nominal variables:\", list(X_train_nominal.columns))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2.2. Irrelevant and constant attributes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.2.2.1. Elimination of irrelevant attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# We take out the EmproyeeID column from the numerical variables group since its an identifier \n",
        "X_train_num = X_train_num.drop('EmployeeID', axis=1)\n",
        "X_train_num.columns"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.2.2.2. Elimination of constant attributes"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4.2.2.2.1. Constant numerical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_num = X_train_num.drop('StandardHours', axis=1)\n",
        "print(list(X_train_num.columns))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_num = X_train_num.drop('EmployeeCount', axis=1)\n",
        "print(list(X_train_num.columns))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### 4.2.2.2.2. Constant categorical attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train_nominal = X_train_nominal.drop ('Over18', axis=1)\n",
        "print(list(X_train_nominal.columns))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "doJuawJZEEhR"
      },
      "source": [
        "## 4.3. Train-Test Error metrics\n",
        "\n",
        "For classification problems, the most common metrics used to evaluate the performance of a model are accuracy, precision, recall, and F1 score. However, these metrics are not always the best choice for evaluating the performance of a model, especially when the dataset is imbalanced.<br>In this case, we will be using the following metrics to evaluate the performance of our models: **balanced accuracy, F1 score, and confusion matrix**."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Please note that for this evaluation, we have utilized the 5th fold generated during model training. This approach enables us to simulate test results without utilizing the actual test set, thereby providing an estimate of the model's accuracy once chosen. Specifically, we use the training data division of the 5th fold as our training data within the function, and the validation data of the 5th fold as our testing partintion. This method ensures an aproximation to reliable and trustworthy results without needing to use the real test partition, enabling us to estimate the model's accuracy before deployment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7EurnrmoEEhR"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import balanced_accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "def train_validation_test(model, estimators, X_train, y_train, folds_array, test = False, X_test = None, y_test = None):\n",
        "    \n",
        "    # ? For every model, we will obtain the balanced_accuracy, the f1_score and the confusion matrix\n",
        "    \n",
        "    # Train\n",
        "    y_train_pred = estimators.predict(X_train)\n",
        "    balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
        "    f1_train = f1_score(y_train, y_train_pred, pos_label='Yes')\n",
        "    cm_train = confusion_matrix(y_train, y_train_pred)\n",
        "     \n",
        "\n",
        "    # Test\n",
        "    if test:\n",
        "        y_test_pred = estimators.predict(X_test)\n",
        "        balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
        "        f1_test = f1_score(y_test, y_test_pred, pos_label='Yes')\n",
        "        cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "    \n",
        "    # We retrain the model with the last obtained fold\n",
        "    np.random.seed(2)\n",
        "    \n",
        "    X_train_fold, y_train_fold, X_validation_fold, y_validation_fold = folds_array[0], folds_array[2], folds_array[1], folds_array[3]\n",
        "\n",
        "    model.fit(X = X_train_fold, y = y_train_fold)\n",
        "    \n",
        "    # Train in validation fold\n",
        "    y_train_validation_pred = model.predict(X_train_fold)\n",
        "    balanced_accuracy_train_validation = balanced_accuracy_score(y_train_fold, y_train_validation_pred)\n",
        "    f1_train_validation = f1_score(y_train_fold, y_train_validation_pred, pos_label='Yes')\n",
        "    cm_train_validation = confusion_matrix(y_train_fold, y_train_validation_pred)\n",
        "\n",
        "    # Test in validation fold\n",
        "    y_test_validation_pred = model.predict(X_validation_fold)\n",
        "    balanced_accuracy_test_validation = balanced_accuracy_score(y_validation_fold, y_test_validation_pred)\n",
        "    f1_test_validation = f1_score(y_validation_fold, y_test_validation_pred, pos_label='Yes')\n",
        "    cm_test_validation = confusion_matrix(y_validation_fold, y_test_validation_pred)\n",
        "    \n",
        "    # ! Print results\n",
        "    # Get the name of the model inside the estimators pipeline\n",
        "    print(\"\\n--------------------\\n\")\n",
        "    print(f\"MODEL: {model.best_estimator_.steps[-1][1]}\")\n",
        "    print(f\"MODEL PARAMETERS: {model.best_params_}\\n\")\n",
        "    # print(model)\n",
        "    print(\"\\n--------------------\\n\")\n",
        "\n",
        "    print(f\"TRAIN SET\")\n",
        "    print(f\"Balanced accuracy in train set: {balanced_accuracy_train}\")\n",
        "    print(f\"F1 score in train set: {f1_train}\")\n",
        "    print(f\"Confusion matrix in train set:\\n {cm_train}\")\n",
        "    print(\"\\n--------------------\\n\")\n",
        "    \n",
        "    if test:\n",
        "        print(f\"TEST SET\")\n",
        "        print(f\"Balanced accuracy in test set: {balanced_accuracy_test}\")\n",
        "        print(f\"F1 score in test set: {f1_test}\")\n",
        "        print(f\"Confusion matrix in test set:\\n {cm_test}\")\n",
        "        print(\"\\n--------------------\\n\")\n",
        "    \n",
        "    print(f\"TRAIN VALIDATION SET\")\n",
        "    print(f\"Balanced accuracy in train validation set: {balanced_accuracy_train_validation}\")\n",
        "    print(f\"F1 score in train validation set: {f1_train_validation}\")\n",
        "    print(f\"Confusion matrix in train validation set:\\n {cm_train_validation}\")\n",
        "    print(\"\\n--------------------\\n\")\n",
        "    \n",
        "    print(f\"TEST VALIDATION SET\")\n",
        "    print(f\"Balanced accuracy in test validation set: {balanced_accuracy_test_validation}\")\n",
        "    print(f\"F1 score in test validation set: {f1_test_validation}\")\n",
        "    print(f\"Confusion matrix in test validation set:\\n {cm_test_validation}\")\n",
        "    print(\"\\n--------------------\\n\")\n",
        "    \n",
        "    if test:\n",
        "        return([[balanced_accuracy_train, f1_train, cm_train], [balanced_accuracy_train_validation, f1_train_validation, cm_train_validation], [balanced_accuracy_test_validation, f1_test_validation, cm_test_validation], [balanced_accuracy_test, f1_test, cm_test]])\n",
        "    return([[balanced_accuracy_train, f1_train, cm_train], [balanced_accuracy_train_validation, f1_train_validation, cm_train_validation], [balanced_accuracy_test_validation, f1_test_validation, cm_test_validation]])\n",
        "     "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OSmgBXtgEEhR"
      },
      "source": [
        "### 4.3.1. Print data distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWrG-RKzEEhR"
      },
      "outputs": [],
      "source": [
        "def print_data_distribution(folds_array):\n",
        "    \"\"\"Print the split of the last fold to check the correct distribution of the data\"\"\"\n",
        "    print(\n",
        "        \"Train:\",\n",
        "        folds_array[0].shape,\n",
        "        \"Train-y:\",\n",
        "        folds_array[2].shape,\n",
        "        \"Validation:\",\n",
        "        folds_array[1].shape,\n",
        "        \"Validation-y:\",\n",
        "        folds_array[3].shape,\n",
        "        sep=\" | \",\n",
        "    )\n",
        "\n",
        "    # Print the distribution of the target variable in the train and validation sets\n",
        "    print(\n",
        "        f\"\\nTrain-y:\\n{folds_array[2].value_counts(normalize=True)}\",\n",
        "        f\"Validation-y:\\n{folds_array[3].value_counts(normalize=True)}\\n\",\n",
        "        sep=\"\\n\\n\",\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DVjoCeNHEEhR"
      },
      "source": [
        "---\n",
        "# 5. Model construction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fSfHMdugEEhR"
      },
      "source": [
        "<mark>(1.3 puntos) Construcción de modelos: para esta práctica usaremos\n",
        "LogisticRegression como método base (sin ajustar hiper-parámetros) y Boosting\n",
        "como método avanzado (ajustando hiper-parámetros), a elegir. Es importante \n",
        "realizar los preprocesos que los datos necesiten, usando preferentemente \n",
        "pipelines. Como método de boosting, se puede elegir uno de entre los métodos de \n",
        "boosting disponibles en scikit-learn. Si además se usa uno de entre las librerías \n",
        "externas xgboost, lightgbm o catboost, se pueden sacar +0.35 puntos adicionale</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnNm_jjOEEhS"
      },
      "source": [
        "<mark>(0.8 puntos) Usando algún método de selección de atributos de tipo filter\n",
        "(SelectKBest) de entre los disponibles en sklearn (f_classif, \n",
        "mutual_info_classif o chi2), comprobad si se pueden mejorar los resultados del \n",
        "apartado anterior y extraer conclusiones sobre qué atributos son más importantes, \n",
        "al menos de acuerdo a estos métodos</mark>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDkHgkZtEEhS"
      },
      "outputs": [],
      "source": [
        "# Three dictionaries to store the results of the models\n",
        "models, results, times = {}, {}, {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a63Hh9wrEEhS"
      },
      "source": [
        "## 5.0. Previous considerations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVsOxjGIEEhS"
      },
      "source": [
        "### 5.0.1. Categorical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjoNF4byEEhS"
      },
      "source": [
        "For the **categorical variables**, we will use **one-hot encoding** to transform them into numerical attributes. One-hot encoding is a commonly used technique for converting categorical attributes into numerical attributes that can be used by a machine learning model. One-hot encoding creates a new binary attribute for each possible category of each categorical attribute. The value of the new binary attribute is 1 if the instance has that category, and 0 otherwise. This increases the complexity of the dataset, but it is necessary for the model to be able to interpret the categorical attributes in sklearn.\n",
        "\n",
        "Additionaly, there is no need for scaling the data, as scales the features to have a mean of 0 and a standard deviation of 1, which is not applicable to categorical features that have been one-hot-encoded."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1rE_43XoEEhS"
      },
      "source": [
        "Note that we could also use label encoding to transform the categorical attributes into numerical attributes. However, one-hot encoding, is generally preferred over label encoding for categorical variables in machine learning because it avoids introducing false numerical relationships between categories."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr7zm7ddEEhS"
      },
      "source": [
        "#### 5.0.1.1. Nominal variables\n",
        "\n",
        "As expected, we will use in the pipeline the **one-hot encoding** technique to transform the nominal variables into numerical attributes. Then we will use SimpleImputer to impute the missing values in the dataset, using the most frequent value for each attribute (as we are dealing with categorical attributes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tIClBwCGEEhS"
      },
      "source": [
        "#### 5.0.1.1. Ordinal variables\n",
        "\n",
        "As expected, we will use in the pipeline the **one-hot encoding** technique to transform the ordinal variables into numerical attributes. Then we will use SimpleImputer to impute the missing values in the dataset, using the most frequent value for each attribute (as we are dealing with categorical attributes).\n",
        "\n",
        "We could use for categorical variables the **ordinal encoding** technique to transform the ordinal variables into numerical attributes. However, we will use one-hot encoding for all categorical variables for the sake of simplicity.\n",
        "\n",
        "<mark>NOTA LO MISMO ES MEJOR USAR ORDINAL ENCODING</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0cRdOoJEEhS"
      },
      "source": [
        "### 5.0.2. Numerical variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx4qsIYbEEhT"
      },
      "source": [
        "For numerical attributes, we will use **IterativeImputer** to impute the missing values in the dataset. This imputer uses a machine learning model to estimate the missing values. It works by modeling each feature with missing values as a function of other features in a round-robin fashion.\n",
        "The advantage is that it can **capture non-linear relationships** between features, and it is also able to impute missing values for multiple features simultaneously (which is not possible with SimpleImputer).\n",
        "On the other hand, the disadvantage is that it is computationally expensive, but, as we are dealing with a relatively **small dataset**, this is not a problem.\n",
        "\n",
        "Note that in sklearn, the IterativeImputer class is still experimental, so we will use the **IterativeImputer** class from the **sklearn.experimental** module.\n",
        "\n",
        "Note also that the IterativeImputer in scikit-learn is designed to work with numerical data only. It uses a linear regression model to estimate missing values based on the other features in the dataset. Therefore, it is not appropriate to use IterativeImputer for imputing missing values in categorical data.\n",
        "\n",
        "Additionally, we will use **StandardScaler** to scale the numerical attributes. This scaler standardizes features by removing the mean and scaling to unit variance. This is done to ensure that each attribute contributes approximately proportionately to the final distance. This is especially important for datasets with numerical attributes of different scales, as we have observed some of them in the EDA process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOzwzbt_EEhT"
      },
      "source": [
        "### 5.0.3. Attribute selection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "OHQmngS8EEhT"
      },
      "source": [
        "When selecting features for a machine learning model, there are several methods available to choose from. Three commonly used methods are f_classif, mutual_info_classif, and chi2. Each of these methods uses a different approach to select the most important features for the model.\n",
        "\n",
        "The `f_classif` method is based on the ANOVA F-value and assumes that the features are normally distributed and there is a linear relationship between the features and the target variable. This means that it may not be the best choice for datasets that contain non-linear relationships between the features and the target variable. However, if the data does meet these assumptions, this method can be a reliable way to select the top k features with the highest scores.\n",
        "\n",
        "On the other hand, the `mutual_info_classif` method estimates the mutual information between each feature and the target variable, which can capture non-linear relationships and does not assume any specific distribution for the features. This method is useful when the relationship between the features and the target variable is not linear or when the data contains non-normally distributed features.\n",
        "\n",
        "Finally, the `chi2` method is suitable for datasets with categorical features and assumes that the features are independent of each other. This method computes the chi-squared statistic between each feature and the target variable, and selects the top k features with the highest scores. However, it may not be the best choice for datasets that contain continuous features or non-independent categorical features.\n",
        "\n",
        "The `mutual_info_classif` method is a suitable choice for selecting features in a machine learning model when the relationships between the features and the target variable are non-linear or when the data contains non-normally distributed features. Unlike the f_classif method, it does not assume any specific distribution for the features and can capture non-linear relationships between the features and the target variable. Additionally, it can handle continuous as well as categorical features.\n",
        "\n",
        "Therefore, if the dataset contains non-linear relationships or non-normally distributed features (as it is our case), the `mutual_info_classif` method may be a more appropriate, and it is the one we are going to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Q8JCj1sEEhT"
      },
      "source": [
        "### 5.0.4. Model validation split obtention\n",
        "The validation split for the models was obtained using the 5th (last) fold of the StratifiedKFold cross-validation method. We chose the 5th fold arbitrarily, since the nature of StratifiedKFold ensures that all folds are representative of the data distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Y3irTqMEEhT"
      },
      "outputs": [],
      "source": [
        "\"\"\" StratifieldKFold that stores the last split as the validation set \"\"\"\n",
        "\n",
        "# We could use whatever split due to the nature of StratifiedKFold, so the decision is arbitrary\n",
        "def stratified_kfold_last_split(folds_array):\n",
        "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=2)\n",
        "    for train_index, test_index in skf.split(X_train, y_train):\n",
        "        # Note that the target variable is \"Attrition\"\n",
        "        # Extract the features (X) and target (y) from the training and test sets\n",
        "        X_train_fold, X_val_fold = X_train.iloc[train_index], X_train.iloc[test_index]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_index], y_train.iloc[test_index]\n",
        "    # Insert the folds in the array\n",
        "    # This is possible because python passes data by reference so we do not need to return the array (not possible in cv)\n",
        "    folds_array.append(X_train_fold); folds_array.append(X_val_fold); folds_array.append(y_train_fold); folds_array.append(y_val_fold)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_lvzdnmEEhT"
      },
      "source": [
        "## 5.1. Logistic Regression\n",
        "Logistic regression with no hyperparameter tuning. It will be used as a baseline for the rest of the models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i1Q2I_J-EEhT"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, KNNImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectKBest, SelectPercentile, mutual_info_classif"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DR7OttIBEEhT"
      },
      "source": [
        "### 5.1.1. Logistic Regression - Predefined parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRtm-C6jEEhT"
      },
      "source": [
        "#### 5.1.1.1. Logistic Regression - Predefined parameters - No attribute selection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "PqVc1SMFD9B4"
      },
      "source": [
        "We have structured in a way that let us use three different pipelines, one for each attribute data type (non-ordinal object, ordinal object, numerical). These pipelines provide a solution for the missing values identified during the EDA section. All pipelines have a two-step process: first, we impute the missing values, and then we scale/encode the results.\n",
        "\n",
        "**Pipeline 1: Imputation**\n",
        "\n",
        "1. For numerical variables, we have chosen to impute missing values using `IterativeImputer`. This imputer provides a powerful and flexible approach to imputing missing values in datasets with complex patterns of missing data and mixed data types. The `IterativeImputer` uses a regression model to estimate missing values, which allows it to take into account the relationships between variables in the dataset. This method can help preserve the structure and relationships of the data while filling in missing values.\n",
        "\n",
        "2. <mark>For categorical variables (ordinal and non-ordinal), we have decided to use `SimpleImputer` as it is the most recommended method for categorical variables. We considered using `KNNImputer`, but this method works best when there are large numbers of options. Since we do not have many variables with a large number of categories, we have decided not to use it.</mark>\n",
        "\n",
        "**Pipeline 2: Scaling/Encoding**\n",
        "\n",
        "1. For numerical variables, we have decided to use `StandardScaler()` to normalize the scale of the numerical features and prevent any large differences in magnitude from dominating the model fitting process. This ensures that each feature contributes equally to the logistic regression model and improves the stability and convergence of the optimization algorithm.\n",
        "\n",
        "2. For non-ordinal categorical variables, we have decided to use `OneHotEncoder`. This encoder creates binary variables for each category in the original variable, which can help avoid assumptions about the underlying structure of the data and improve the accuracy of the model. Other encoders, such as `LabelEncoder` or `OrdinalEncoder`, are not recommended for nominal categorical variables as they can introduce spurious order or hierarchy to the categories. Additionally, these encoders may not be suitable for logistic regression models as they assume a linear relationship between the encoded values and the target variable, which may not be appropriate for categorical variables.\n",
        "\n",
        "3. For ordinal categorical variables, we have decided to use `OrdinalEncoder` since it preserves the order of the categories and converts them into numerical values that can be used in the logistic regression model. This ensures that the model can accurately capture the relationship between the ordinal categories and the target variable. Additionally, the `OrdinalEncoder` can handle missing values in the ordinal variables, which is important for ensuring that the imputation process does not introduce bias into the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GTIFQiUyEEhT"
      },
      "outputs": [],
      "source": [
        "np.random.seed(2)\n",
        "\n",
        "# ? Pipeline for numerical values (X_train_num)\n",
        "imputer_num = IterativeImputer(\n",
        "    random_state=2,\n",
        "    missing_values=np.nan,\n",
        ")\n",
        "pipeline_lr_num = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_num),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? One hot encoding the categorical variables\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        (\"imputer\", imputer_cat)\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? We add a second pipeline for ordinal categorical variables \n",
        "imputer_cat_ord = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat_ord = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown='error')),\n",
        "        (\"imputer\", imputer_cat_ord)\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hsXMbs4kEEhU"
      },
      "outputs": [],
      "source": [
        "\"\"\" Column transformer to apply the pipelines to the correct columns \"\"\"\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", pipeline_lr_num, X_train_num.columns), # X_train_num.columns for numerical values\n",
        "        (\"cat\", pipeline_lr_cat, X_train_nominal.columns), # X_train_nominal.columns for categorical values (not ordinals)\n",
        "        (\"ord\", pipeline_lr_cat_ord, X_train_ordinals.columns)  # X_train_ordinals.columns for categorical ordinal values \n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkd-fNOuEEhU"
      },
      "outputs": [],
      "source": [
        "\"\"\" Append classifier to preprocessing pipeline \"\"\"\n",
        "\n",
        "preprocessing_pipeline_lr = Pipeline(\n",
        "    steps = [\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", LogisticRegression(random_state=2, class_weight='balanced')),        \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjdiUg7BEEhU",
        "outputId": "99f13d52-ba98-4e6d-da0f-1f97ca99658f"
      },
      "outputs": [],
      "source": [
        "\"\"\" Logistic Regression with the default parameters \"\"\"\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"model__penalty\": [\"l2\"],\n",
        "    \"model__C\": [1.0],\n",
        "    \"model__fit_intercept\": [True],\n",
        "    \"model__solver\": [\"lbfgs\"],\n",
        "    \"model__max_iter\": [100],\n",
        "    \"model__multi_class\": [\"auto\"],\n",
        "}\n",
        "\n",
        "folds_array = []\n",
        "\n",
        "model_lr = GridSearchCV(\n",
        "    preprocessing_pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=stratified_kfold_last_split(folds_array),\n",
        "    scoring=\"balanced_accuracy\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "model_lr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "time_lr = end_time - start_time\n",
        "\n",
        "print_data_distribution(folds_array)\n",
        "\n",
        "# Print the best model and its performance\n",
        "print(\n",
        "    \"Logistic regression\",\n",
        "    # model_lr,\n",
        "    model_lr.best_score_,\n",
        "    # model_lr.best_params_,\n",
        "    # time_lr,\n",
        ")\n",
        "\n",
        "score = train_validation_test(model_lr, model_lr.best_estimator_, X_train, y_train, folds_array) #, X_test, y_test, test=True)\n",
        "print(f\"TOTAL FIT TIME: {time_lr}\")\n",
        "\n",
        "models[\"Logistic_Regression_pred\"] = model_lr\n",
        "results[\"Logistic_Regression_pred\"] = score\n",
        "times[\"Logistic_Regression_pred\"] = time_lr\n",
        "\n",
        "# print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boiBcTvDEEhU"
      },
      "source": [
        "#### 5.1.1.2. Logistic Regression - Predefined parameters - Attribute selection"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "jaUlNK7bEEhU"
      },
      "source": [
        "<mark> SELECCIONAR 1 selector y porq </mark>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uPF8mIwEEhU"
      },
      "outputs": [],
      "source": [
        "\"\"\" Logistic Regression with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "# ? Pipeline for numerical values (X_train_num)\n",
        "imputer_num = IterativeImputer(\n",
        "    random_state=2,\n",
        "    missing_values=np.nan,\n",
        ")\n",
        "pipeline_lr_num = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_num),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)), # ? Feature selection with mutual_info_classif\n",
        "        # (\"selector2\", SelectPercentile(mutual_info_classif, percentile=50)), # ? Feature selection with chi2\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? One hot encoding the categorical variables\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        (\"imputer\", imputer_cat),\n",
        "        \n",
        "        # (\"selector\", SelectKBest(mutual_info_classif, k=10)), # ? Feature selection with mutual_info_classif\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)), # ? Feature selection with mutual_info_classif\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? We add a second pipeline for ordinal categorical variables \n",
        "imputer_cat_ord = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat_ord = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown='error')),\n",
        "        (\"imputer\", imputer_cat_ord),\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DhWtrGcSEEhU",
        "outputId": "e399fc9e-e3c7-4261-ac14-8d892f4f8dd3"
      },
      "outputs": [],
      "source": [
        "\"\"\" Logistic Regression with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"model__penalty\": [\"l2\"],\n",
        "    \"model__C\": [1.0],\n",
        "    \"model__fit_intercept\": [True],\n",
        "    \"model__solver\": [\"lbfgs\"],\n",
        "    \"model__max_iter\": [100],\n",
        "    \"model__multi_class\": [\"auto\"],\n",
        "}\n",
        "\n",
        "folds_array = []\n",
        "\n",
        "model_lr = GridSearchCV(\n",
        "    preprocessing_pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=stratified_kfold_last_split(folds_array),\n",
        "    scoring=\"balanced_accuracy\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "\n",
        "start_time = time.time()\n",
        "model_lr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "time_lr = end_time - start_time\n",
        "\n",
        "\n",
        "print_data_distribution(folds_array)\n",
        "\n",
        "# Print the best model and its performance\n",
        "print(\n",
        "    \"Logistic regression\",\n",
        "    # model_lr,\n",
        "    model_lr.best_score_,\n",
        "    # model_lr.best_params_,\n",
        "    # time_lr,\n",
        ")\n",
        "\n",
        "score = train_validation_test(model_lr, model_lr.best_estimator_, X_train, y_train, folds_array) #, X_test, y_test, test=True)\n",
        "print(f\"TOTAL FIT TIME: {time_lr}\")\n",
        "\n",
        "models[\"Logistic_Regression_pred_k\"] = model_lr\n",
        "results[\"Logistic_Regression_pred_k\"] = score\n",
        "times[\"Logistic_Regression_pred_k\"] = time_lr\n",
        "\n",
        "# print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBIBBmk0EEhV"
      },
      "source": [
        "## 5.2. Boosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XI52b-RIEEhV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "import time\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_selection import SelectPercentile, chi2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yHK-Y3pDEEhV"
      },
      "source": [
        "<mark>Como método de boosting, se puede elegir uno de entre los métodos de \n",
        "boosting disponibles en scikit-learn. Si además se usa uno de entre las librerías \n",
        "externas xgboost, lightgbm o catboost, se pueden sacar +0.35 puntos adicionales.</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRfk9ADGEEhV"
      },
      "source": [
        "### 5.2.1. Boosting - Predefined parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jarunvIdEEhV"
      },
      "source": [
        "#### 5.2.1.1. Boosting - Predefined parameters - No attribute selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w-cDIL9sEEhV"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient Boosting Classifier with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "# ? Pipeline for numerical values (X_train_num)\n",
        "imputer_num = IterativeImputer(\n",
        "    random_state=2,\n",
        "    missing_values=np.nan,\n",
        ")\n",
        "pipeline_lr_num = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_num),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? One hot encoding the categorical variables\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        (\"imputer\", imputer_cat),\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")\n",
        "\n",
        " # ? We add a second pipeline for ordinal categorical variables \n",
        "imputer_cat_ord = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat_ord = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown='error')),\n",
        "        (\"imputer\", imputer_cat_ord)\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diPZVx-KEEhV"
      },
      "outputs": [],
      "source": [
        "\"\"\" Column transformer to apply the pipelines to the correct columns \"\"\"\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", pipeline_lr_num, X_train_num.columns), # X_train_num.columns for numerical values\n",
        "        (\"cat\", pipeline_lr_cat, X_train_nominal.columns), # X_train_str.columns for categorical values\n",
        "        (\"ord\", pipeline_lr_cat_ord, X_train_ordinals.columns)# X_train_ordinals.columns for categorical ordinal values\n",
        "    ],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNfptZOnEEhV"
      },
      "outputs": [],
      "source": [
        "\"\"\" Append classifier to preprocessing pipeline \"\"\"\n",
        "\n",
        "preprocessing_pipeline_lr = Pipeline(\n",
        "    steps = [\n",
        "        (\"preprocessor\", preprocessor),\n",
        "        (\"model\", GradientBoostingClassifier(random_state=2)),        \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a0i_LgW1EEhV",
        "outputId": "7057dd2b-9a2e-4b12-c35c-68d717511654"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient boosting with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"model__n_estimators\": [100],\n",
        "    \"model__learning_rate\": [0.1],\n",
        "    \"model__max_depth\": [3],\n",
        "    \"model__subsample\": [1.0],\n",
        "    \"model__min_samples_split\": [2],\n",
        "}\n",
        "\n",
        "folds_array = []\n",
        "\n",
        "model_lr = GridSearchCV(\n",
        "    preprocessing_pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=stratified_kfold_last_split(folds_array),\n",
        "    scoring=\"balanced_accuracy\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "model_lr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "time_lr = end_time - start_time\n",
        "\n",
        "# ! NS porq me da mejor simple imputer que el otro, pero vaya de 0.002 (0.6987387505335906 - 0.7005306394679833)\n",
        "\n",
        "print_data_distribution(folds_array)\n",
        "\n",
        "# Print the best model and its performance\n",
        "print(\n",
        "    \"Logistic regression\",\n",
        "    # model_lr,\n",
        "    model_lr.best_score_,\n",
        "    # model_lr.best_params_,\n",
        "    # time_lr,\n",
        ")\n",
        "\n",
        "score = train_validation_test(model_lr, model_lr.best_estimator_, X_train, y_train, folds_array) #, X_test, y_test, test=True)\n",
        "print(f\"TOTAL FIT TIME: {time_lr}\")\n",
        "\n",
        "models[\"Gradient_boosting_pred\"] = model_lr\n",
        "results[\"Gradient_boosting_pred\"] = score\n",
        "times[\"Gradient_boosting_pred\"] = time_lr\n",
        "\n",
        "\n",
        "# print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V65xVAxSEEhW"
      },
      "source": [
        "#### 5.2.1.2. Boosting - Predefined parameters - Attribute selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c3q9qZOiKTB"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient Boosting Classifier with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "# ? Pipeline for numerical values (X_train_num)\n",
        "imputer_num = IterativeImputer(\n",
        "    random_state=2,\n",
        "    missing_values=np.nan,\n",
        ")\n",
        "pipeline_lr_num = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_num),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)), # ? Feature selection with mutual_info_classif\n",
        "        # (\"selector2\", SelectPercentile(mutual_info_classif, percentile=50)), # ? Feature selection with chi2\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? One hot encoding the categorical variables\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_cat),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        # (\"selector\", SelectKBest(mutual_info_classif, k=10)), # ? Feature selection with mutual_info_classif\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)), # ? Feature selection with mutual_info_classif\n",
        "    ]\n",
        ")\n",
        "\n",
        " # ? We add a second pipeline for ordinal categorical variables \n",
        "imputer_cat_ord = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat_ord = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown='error')),\n",
        "        (\"imputer\", imputer_cat_ord),\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a3USei4EEhW",
        "outputId": "6824633b-d1dd-4d0d-c529-7db3ed218651"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient boosting with the default parameters \"\"\"\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"model__n_estimators\": [100],\n",
        "    \"model__learning_rate\": [0.1],\n",
        "    \"model__max_depth\": [3],\n",
        "    \"model__subsample\": [1.0],\n",
        "    \"model__min_samples_split\": [2],\n",
        "}\n",
        "\n",
        "folds_array = []\n",
        "\n",
        "model_lr = GridSearchCV(\n",
        "    preprocessing_pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=stratified_kfold_last_split(folds_array),\n",
        "    scoring=\"balanced_accuracy\",\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "model_lr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "time_lr = end_time - start_time\n",
        "\n",
        "# ! NS porq me da mejor simple imputer que el otro, pero vaya de 0.002 (0.6987387505335906 - 0.7005306394679833)\n",
        "\n",
        "print_data_distribution(folds_array)\n",
        "\n",
        "# Print the best model and its performance\n",
        "print(\n",
        "    \"Logistic regression\",\n",
        "    # model_lr,\n",
        "    model_lr.best_score_,\n",
        "    # model_lr.best_params_,\n",
        "    # time_lr,\n",
        ")\n",
        "\n",
        "score = train_validation_test(model_lr, model_lr.best_estimator_, X_train, y_train, folds_array) #, X_test, y_test, test=True)\n",
        "print(f\"TOTAL FIT TIME: {time_lr}\")\n",
        "\n",
        "models[\"Gradient_boosting_pred_k\"] = model_lr\n",
        "results[\"Gradient_boosting_pred_k\"] = score\n",
        "times[\"Gradient_boosting_pred_k\"] = time_lr\n",
        "\n",
        "# print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szYro1peEEhW"
      },
      "source": [
        "### 5.2.2. Boosting - Selected parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x83IDQf7EEhW"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afmHmAlSEEhW"
      },
      "source": [
        "#### 5.2.2.1. Boosting - Selected parameters - No attribute selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C8us-LZXEEhW"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient Boosting Classifier with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "# ? Pipeline for numerical values (X_train_num)\n",
        "imputer_num = IterativeImputer(\n",
        "    random_state=2,\n",
        "    missing_values=np.nan,\n",
        ")\n",
        "pipeline_lr_num = Pipeline(\n",
        "    steps=[\n",
        "        # (\"imputer\", SimpleImputer(missing_values=np.nan, strategy=\"median\")), # ? Simple imputer with median\n",
        "        (\"imputer\", imputer_num),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? One hot encoding the categorical variables\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_cat),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        " # ? We add a second pipeline for ordinal categorical variables \n",
        "imputer_cat_ord = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat_ord = Pipeline(\n",
        "    steps=[\n",
        "        (\"encoder\", OrdinalEncoder(handle_unknown='error')),\n",
        "        (\"imputer\", imputer_cat_ord),\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "       \n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVQBHAzDEEhW",
        "outputId": "36c6a4a5-ab7f-421b-e598-654e70b8d710"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient boosting with the default parameters \"\"\"\n",
        "\n",
        "budget = 10\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"model__n_estimators\": [50, 100, 200],\n",
        "    \"model__learning_rate\": [0.01, 0.1, 1.0],\n",
        "    \"model__max_depth\": [2, 3, 4],\n",
        "    \"model__subsample\": [0.5, 0.8, 1.0],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "}\n",
        "\n",
        "folds_array = []\n",
        "\n",
        "model_lr = RandomizedSearchCV(\n",
        "    preprocessing_pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=stratified_kfold_last_split(folds_array),\n",
        "    scoring=\"balanced_accuracy\",\n",
        "    n_iter=budget,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "model_lr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "time_lr = end_time - start_time\n",
        "\n",
        "# ! NS porq me da mejor simple imputer que el otro, pero vaya de 0.002 (0.6987387505335906 - 0.7005306394679833)\n",
        "\n",
        "print_data_distribution(folds_array)\n",
        "\n",
        "# Print the best model and its performance\n",
        "print(\n",
        "    \"Logistic regression\",\n",
        "    # model_lr,\n",
        "    model_lr.best_score_,\n",
        "    # model_lr.best_params_,\n",
        "    # time_lr,\n",
        ")\n",
        "\n",
        "score = train_validation_test(model_lr, model_lr.best_estimator_, X_train, y_train, folds_array) #, X_test, y_test, test=True)\n",
        "print(f\"TOTAL FIT TIME: {time_lr}\")\n",
        "\n",
        "\n",
        "models[\"Gradient_boosting_select\"] = model_lr\n",
        "results[\"Gradient_boosting_select\"] = score\n",
        "times[\"Gradient_boosting_select\"] = time_lr\n",
        "\n",
        "# print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nIWpaemvEEhX"
      },
      "outputs": [],
      "source": [
        "balanced = []\n",
        "\n",
        "balanced2 = []\n",
        "\n",
        "balanced3 = []\n",
        "\n",
        "balanced4 = []\n",
        "\n",
        "balanced5 = []\n",
        "\n",
        "\n",
        "\n",
        "a_n_estimators = [50, 100, 200]\n",
        "a_learning_rate = [0.01, 0.1, 1.0]\n",
        "a_max_depth = [2, 3, 4]\n",
        "a_subsample = [0.5, 0.8, 1.0]\n",
        "a_min_samples_split = [2, 5, 10]\n",
        "\n",
        "\n",
        "for i in a_n_estimators:\n",
        "    param_grid_lr = {\n",
        "    \"model__n_estimators\": [i],\n",
        "    \"model__learning_rate\": [0.1],\n",
        "    \"model__max_depth\": [3],\n",
        "    \"model__subsample\": [1.0],\n",
        "    \"model__min_samples_split\": [2],\n",
        "    }\n",
        "\n",
        "    folds_array = []\n",
        "\n",
        "    model_lr = GridSearchCV(\n",
        "        preprocessing_pipeline_lr,\n",
        "        param_grid_lr,\n",
        "        cv=stratified_kfold_last_split(folds_array),\n",
        "        scoring=\"balanced_accuracy\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    balanced.append( model_lr.best_score_)\n",
        "    \n",
        "for i in a_learning_rate:\n",
        "    param_grid_lr = {\n",
        "    \"model__n_estimators\": [100],\n",
        "    \"model__learning_rate\": [i],\n",
        "    \"model__max_depth\": [3],\n",
        "    \"model__subsample\": [1.0],\n",
        "    \"model__min_samples_split\": [2],\n",
        "    }\n",
        "\n",
        "    folds_array = []\n",
        "\n",
        "    model_lr = GridSearchCV(\n",
        "        preprocessing_pipeline_lr,\n",
        "        param_grid_lr,\n",
        "        cv=stratified_kfold_last_split(folds_array),\n",
        "        scoring=\"balanced_accuracy\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    balanced2.append( model_lr.best_score_)\n",
        "    \n",
        "for i in a_max_depth:\n",
        "    param_grid_lr = {\n",
        "    \"model__n_estimators\": [100],\n",
        "    \"model__learning_rate\": [0.1],\n",
        "    \"model__max_depth\": [i],\n",
        "    \"model__subsample\": [1.0],\n",
        "    \"model__min_samples_split\": [2],\n",
        "    }\n",
        "\n",
        "    folds_array = []\n",
        "\n",
        "    model_lr = GridSearchCV(\n",
        "        preprocessing_pipeline_lr,\n",
        "        param_grid_lr,\n",
        "        cv=stratified_kfold_last_split(folds_array),\n",
        "        scoring=\"balanced_accuracy\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    balanced3.append( model_lr.best_score_)\n",
        "\n",
        "\n",
        "for i in a_subsample:\n",
        "    param_grid_lr = {\n",
        "    \"model__n_estimators\": [100],\n",
        "    \"model__learning_rate\": [0.1],\n",
        "    \"model__max_depth\": [3],\n",
        "    \"model__subsample\": [i],\n",
        "    \"model__min_samples_split\": [2],\n",
        "    }\n",
        "\n",
        "    folds_array = []\n",
        "\n",
        "    model_lr = GridSearchCV(\n",
        "        preprocessing_pipeline_lr,\n",
        "        param_grid_lr,\n",
        "        cv=stratified_kfold_last_split(folds_array),\n",
        "        scoring=\"balanced_accuracy\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    balanced4.append( model_lr.best_score_)\n",
        "    \n",
        "for i in a_min_samples_split:\n",
        "    param_grid_lr = {\n",
        "    \"model__n_estimators\": [100],\n",
        "    \"model__learning_rate\": [0.1],\n",
        "    \"model__max_depth\": [3],\n",
        "    \"model__subsample\": [1.0],\n",
        "    \"model__min_samples_split\": [i],\n",
        "    }\n",
        "\n",
        "    folds_array = []\n",
        "\n",
        "    model_lr = GridSearchCV(\n",
        "        preprocessing_pipeline_lr,\n",
        "        param_grid_lr,\n",
        "        cv=stratified_kfold_last_split(folds_array),\n",
        "        scoring=\"balanced_accuracy\",\n",
        "        n_jobs=-1,\n",
        "    )\n",
        "\n",
        "    start_time = time.time()\n",
        "    model_lr.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    balanced5.append( model_lr.best_score_)\n",
        "# Crear dos subplots, uno para cada gráfico\n",
        "fig, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(5, 1, figsize=(8, 12))\n",
        "\n",
        "# Graficar RMSE vs. n_neighbors en el primer subplot\n",
        "ax1.plot(a_n_estimators, balanced, label=\"Balanced accuracy\")\n",
        "ax1.set_xlabel(\"n_estimators\")\n",
        "ax1.set_ylabel(\"Balanced accuracy\")\n",
        "ax1.set_title(\"Gráfica de Balanced\")\n",
        "\n",
        "# Graficar MAE vs. n_neighbors en el segundo subplot\n",
        "ax2.plot(a_learning_rate,  balanced2, label=\"Balanced accuracy\")\n",
        "ax2.set_xlabel(\"learning_rate\")\n",
        "ax2.set_ylabel(\"Balanced accuracy\")\n",
        "ax2.set_title(\"Gráfica de Balanced accuracy\")\n",
        "\n",
        "# Graficar RMSE vs. metric en el tercer subplot\n",
        "ax3.plot(a_max_depth,  balanced3, label=\"Balanced accuracy\")\n",
        "ax3.set_xlabel(\"max_depth\")\n",
        "ax3.set_ylabel(\"Balanced accuracy\")\n",
        "ax3.set_title(\"Gráfica de Balanced accuracy\")\n",
        "\n",
        "# Graficar MAE vs. metric en el cuarto subplot\n",
        "ax4.plot(a_subsample ,  balanced4, label=\"Balanced accuracy\")\n",
        "ax4.set_xlabel(\"subsample\")\n",
        "ax4.set_ylabel(\"Balanced accuracy\")\n",
        "ax4.set_title(\"Gráfica de Balanced accuracy\")\n",
        "\n",
        "# Graficar RMSE vs. metric en el tercer subplot\n",
        "ax5.plot(a_min_samples_split, balanced5, label=\"Balanced accuracy\")\n",
        "ax5.set_xlabel(\"min_samples_split\")\n",
        "ax5.set_ylabel(\"Balanced accuracy\")\n",
        "ax5.set_title(\"Gráfica de Balanced accuracy\")\n",
        "\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.rcParams['figure.figsize'] = [10, 3]\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zD-QDPuLEEhX"
      },
      "source": [
        "#### 5.2.2.2. Boosting - Selected parameters - Attribute selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQMnMnANEEhX"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient Boosting Classifier with the default parameters \"\"\"\n",
        "\n",
        "np.random.seed(2)\n",
        "\n",
        "# ? Pipeline for numerical values (X_train_num)\n",
        "imputer_num = IterativeImputer(\n",
        "    random_state=2,\n",
        "    missing_values=np.nan,\n",
        ")\n",
        "pipeline_lr_num = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_num),\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)), # ? Feature selection with mutual_info_classif\n",
        "        # (\"selector2\", SelectPercentile(mutual_info_classif, percentile=50)), # ? Feature selection with chi2\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ? One hot encoding the categorical variables\n",
        "imputer_cat = SimpleImputer(strategy=\"most_frequent\")\n",
        "pipeline_lr_cat = Pipeline(\n",
        "    steps=[\n",
        "        (\"imputer\", imputer_cat),\n",
        "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
        "        # (\"selector\", SelectKBest(mutual_info_classif, k=10)), # ? Feature selection with mutual_info_classif\n",
        "        # (\"selector\", SelectPercentile(chi2, percentile=50)), # ? Feature selection with chi2\n",
        "        (\"selector\", SelectKBest(mutual_info_classif)), # ? Feature selection with mutual_info_classif\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDEOTxIHEEhX",
        "outputId": "fb316ddf-9000-4d86-94dc-c7a3e481aeca"
      },
      "outputs": [],
      "source": [
        "\"\"\" Gradient boosting with the default parameters \"\"\"\n",
        "\n",
        "budget = 10\n",
        "\n",
        "param_grid_lr = {\n",
        "    \"model__n_estimators\": [50, 100, 200],\n",
        "    \"model__learning_rate\": [0.01, 0.1, 1.0],\n",
        "    \"model__max_depth\": [2, 3, 4],\n",
        "    \"model__subsample\": [0.5, 0.8, 1.0],\n",
        "    \"model__min_samples_split\": [2, 5, 10],\n",
        "}\n",
        "\n",
        "folds_array = []\n",
        "\n",
        "model_lr = RandomizedSearchCV(\n",
        "    preprocessing_pipeline_lr,\n",
        "    param_grid_lr,\n",
        "    cv=stratified_kfold_last_split(folds_array),\n",
        "    scoring=\"balanced_accuracy\",\n",
        "    n_iter=budget,\n",
        "    n_jobs=-1,\n",
        ")\n",
        "\n",
        "start_time = time.time()\n",
        "model_lr.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "time_lr = end_time - start_time\n",
        "\n",
        "# ! NS porq me da mejor simple imputer que el otro, pero vaya de 0.002 (0.6987387505335906 - 0.7005306394679833)\n",
        "\n",
        "print_data_distribution(folds_array)\n",
        "\n",
        "# Print the best model and its performance\n",
        "print(\n",
        "    \"Logistic regression\",\n",
        "    # model_lr,\n",
        "    model_lr.best_score_,\n",
        "    # model_lr.best_params_,\n",
        "    # time_lr,\n",
        ")\n",
        "\n",
        "score = train_validation_test(model_lr, model_lr.best_estimator_, X_train, y_train, folds_array) #, X_test, y_test, test=True)\n",
        "print(f\"TOTAL FIT TIME: {time_lr}\")\n",
        "\n",
        "models[\"Gradient_boosting_select_k\"] = model_lr\n",
        "results[\"Gradient_boosting_select_k\"] = score\n",
        "times[\"Gradient_boosting_select_k\"] = time_lr\n",
        "\n",
        "\n",
        "# print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8DFkHgJEEhY"
      },
      "source": [
        "### 5.2.1. Boosting - Predefined parameters - LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4njdn8JaEEhY"
      },
      "source": [
        "#### 5.2.1.1. Boosting - Predefined parameters - No attribute selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-G12Re9CEEhY"
      },
      "source": [
        "#### 5.2.1.2. Boosting - Predefined parameters - Attribute selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYdjERe3EEhY"
      },
      "source": [
        "### 5.2.2. Boosting - Selected parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeTsSaxiEEhY"
      },
      "source": [
        "#### 5.2.2.1. Boosting - Selected parameters - No attribute selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TO19W_O0EEhY"
      },
      "source": [
        "#### 5.2.2.2. Boosting - Selected parameters - Attribute selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0dWiVVZEEhY"
      },
      "source": [
        "<mark>Código en un notebook. Es necesario que a lo largo de la práctica se vayan extrayendo \n",
        "conclusiones, y al final de la práctica, hay que hacer un resumen de todos los resultados \n",
        "obtenidos, usando tablas y/o gráficos.\n",
        "● El archivo conteniendo el mejor modelo obtenido (llamado «modelo_final.pkl»).</mark>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjXk4gdeEEhY"
      },
      "source": [
        "## 5.3. Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbaUCX-GEEhY"
      },
      "source": [
        "---\n",
        "# 6. Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFmPcjM4EEhY"
      },
      "source": [
        "## 8.1. Best Model Selection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lqQS4qMFEEhY"
      },
      "source": [
        "### 8.1.1. Best Model Prediction - Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cn46nm9cEEhZ"
      },
      "source": [
        "## 8.2. Selected Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJdq7cRLEEhZ"
      },
      "source": [
        "### 8.2.1. Selected Model Prediction and Comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t_jJDNacEEhZ"
      },
      "outputs": [],
      "source": [
        "plt.rcParams['figure.figsize'] = [10, 3.5]\n",
        "\n",
        "print(\"MODEL SCORES (Balanced Accuracy Train)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[0][0])\n",
        "    plt.bar(key, abs(value[0][0]))\n",
        "    print(f\"{iter}. {key}: {abs(value[0][0])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Balanced Accuracy Train\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score.png\")\n",
        "plt.show()\n",
        "\n",
        "print(\"MODEL SCORES (F1 Train)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[0][1])\n",
        "    plt.bar(key, abs(value[0][1]))\n",
        "    print(f\"{iter}. {key}: {abs(value[0][1])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"F1 Train\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score2.png\")\n",
        "plt.show()\n",
        "\n",
        "'''print(\"MODEL SCORES (CM Train)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[0][2])\n",
        "    plt.bar(key, abs(value[0][2]))\n",
        "    print(f\"{iter}. {key}: {abs(value[0][2])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"CM Train\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score3.png\")\n",
        "plt.show()\n",
        "'''\n",
        "#---------------------------------------------------------------\n",
        "\n",
        "print(\"MODEL SCORES (Balanced Accuracy Train Validation)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[1][0])\n",
        "    plt.bar(key, abs(value[1][0]))\n",
        "    print(f\"{iter}. {key}: {abs(value[1][0])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Balanced Accuracy Train Validation\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score4.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"MODEL SCORES (F1 Train Validation)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[1][1])\n",
        "    plt.bar(key, abs(value[1][1]))\n",
        "    print(f\"{iter}. {key}: {abs(value[1][1])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"F1 Train Validation\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score5.png\")\n",
        "plt.show()\n",
        "\n",
        "'''print(\"MODEL SCORES (CM Train Validation)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[1][2])\n",
        "    plt.bar(key, abs(value[1][2]))\n",
        "    print(f\"{iter}. {key}: {abs(value[1][2])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"CM Train Validation\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score6.png\")\n",
        "plt.show()'''\n",
        "\n",
        "#----------------------------------------------------------------\n",
        "\n",
        "print(\"MODEL SCORES (Balanced Accuracy Test Validation)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[2][0])\n",
        "    plt.bar(key, abs(value[2][0]))\n",
        "    print(f\"{iter}. {key}: {abs(value[2][0])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Balanced Accuracy Test Validation\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score7.png\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"MODEL SCORES (F1 Test Validation)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[2][1])\n",
        "    plt.bar(key, abs(value[2][1]))\n",
        "    print(f\"{iter}. {key}: {abs(value[2][1])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"F1 Test Validation\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"../data/img/best_methods_score8.png\")\n",
        "plt.show()\n",
        "\n",
        "'''print(\"MODEL SCORES (CM Test Validation)\")\n",
        "iter = 0\n",
        "for key, value in results.items():\n",
        "    print(value[2][2])\n",
        "    plt.bar(key, abs(value[2][2]))\n",
        "    print(f\"{iter}. {key}: {abs(value[2][2])}\")\n",
        "    iter += 1\n",
        "plt.title(\"Score\")\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"CM Test Validation\")\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.xticks(rotation=45, ha='right', size=7)\n",
        "\n",
        "# Exporting image as png to ../data/img folder\n",
        "plt.savefig(\"./best_methods_score9.png\")\n",
        "plt.show()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kv3mqlPJEEha"
      },
      "source": [
        "## 8.3. Selected Model Export"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzHJH3e0EEhb"
      },
      "source": [
        "---\n",
        "# 9. Final Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1y9kpPYcEEhb"
      },
      "source": [
        "During this project, we have had the opportunity to gain a deeper understanding of the model selection process. We began with exploratory data analysis (EDA), which helped us to improve our understanding and management of the data. We found this to be an extremely useful tool throughout the entire project. We believe that this part of the project should be evaluated with greater emphasis, as it is the foundation upon which all of our decisions were based.\n",
        "\n",
        "Next, we created and trained all of our models, gaining experience in the use of pipelines and a deeper understanding of the importance of hyperparameters. Finally, we analyzed the different results provided by each model, gaining a better understanding of their respective advantages and disadvantages in terms of scoring and time.\n",
        "\n",
        "We believe that this project is an excellent complement to the main lessons, as it provides a deeper understanding of the subject matter."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qGioG-5hEEhb"
      },
      "source": [
        "---\n",
        "# X. Output the Jupyter Notebook as an HTML file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vdbNGpuSEEhb",
        "outputId": "a4b00e97-7090-41fd-8f03-785cd42e030a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Export the notebook to HTML\n",
        "os.system(\"jupyter nbconvert --to html model.ipynb --output ../data/html/model.html\")\n",
        "print(\"Notebook exported to HTML\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml_practica_2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.10"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
