{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práctica 1. Aprendizaje Automático\n",
    "\n",
    "Authors: Carlos Iborra Llopis (100451170), Alejandra Galán Arrospide (100451273) <br>\n",
    "For additional notes and requirements: https://github.com/carlosiborra/Grupo02-Practica2-AprendizajeAutomatico\n",
    "\n",
    "❗If you are willing to run the code yourself, please clone the full GitHub repository, as it contains the necessary folder structures to export images and results❗"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Table of contents\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Requirements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Validation splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Importing necessary libraries \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import scipy\n",
    "import sklearn\n",
    "\n",
    "from matplotlib.cbook import boxplot_stats as bps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Cleaning ../data/img/ folder\n",
    "This way we avoid creating multiple images and sending the old ones to the trash.<br>\n",
    "Also using this to upload cleaner commits to GitHub.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Cleaning the ../data/img/ folder \"\"\"\n",
    "import os\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"../data/img/*\")\n",
    "for f in files:\n",
    "    if os.path.isfile(f) and f.endswith(\".png\"):\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Reading the datasets\n",
    "Reading the datasets from the bz2 files, group 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('../data/attrition_available_2.pkl', 'rb') as pkl_file:\n",
    "    datos = pickle.load(pkl_file)\n",
    "\n",
    "datos # TODO: FIX THIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the data to a csv file\n",
    "datos.to_csv('../data/attrition_available_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. EDA"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>(0,15 puntos) Hacer un EDA muy simplificado: cuántas instancias / cuantos \n",
    "atributos y de qué tipo (numéricos, ordinales, categóricos); columnas constantes o \n",
    "innecesarias; que proporción de missing values por atributo; tipo de problema: \n",
    "(clasificación o regresión); ¿es desbalanceado?</mark>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Key Concepts of Exploratory Data Analysis**\n",
    "\n",
    "- **2 types of Data Analysis**\n",
    "  - Confirmatory Data Analysis\n",
    "  - Exploratory Data Analysis\n",
    "- **4 Objectives of EDA**\n",
    "  - Discover Patterns\n",
    "  - Spot Anomalies\n",
    "  - Frame Hypothesis\n",
    "  - Check Assumptions\n",
    "- **2 methods for exploration**\n",
    "  - Univariate Analysis\n",
    "  - Bivariate Analysis\n",
    "- **Stuff done during EDA**\n",
    "  - Trends\n",
    "  - Distribution\n",
    "  - Mean\n",
    "  - Median\n",
    "  - Outlier\n",
    "  - Spread measurement (SD)\n",
    "  - Correlations\n",
    "  - Hypothesis testing\n",
    "  - Visual Exploration\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.0. Dataset preparation\n",
    "\n",
    "To conduct exploratory data analysis (EDA) on our real data, we need to prepare the data first. Therefore, we have decided to separate the data into training and test sets at an early stage to avoid data leakage, which could result in an overly optimistic evaluation of the model, among other consequences. This separation will be done by dividing the data prematurely into training and test sets since potential data leakage can occur from the usage of the test partition, especially when including the result variable.\n",
    "\n",
    "It is important to note that this step is necessary because all the information obtained in this section will be used to make decisions such as dimensionality reduction. Furthermore, this approach makes the evaluation more realistic and rigorous since the test set is not used until the end of the process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.0.1. Stratified K-Fold\n",
    "To ensure a fair and unbiased evaluation of our model's performance, we will be using stratified k-fold for dividing our data into training and test sets. Stratified k-fold is a commonly used technique in machine learning that ensures that the distribution of classes in the training and test sets is similar, thus reducing the risk of introducing bias into our model's performance evaluation.\n",
    "\n",
    "By using stratified k-fold, we can ensure that each fold of the data used for training and testing our model contains a representative sample of all the classes in the dataset. This helps to account for any potential class imbalance in the data, ensuring that our model is trained and tested on a diverse set of data, leading to a more reliable evaluation of its performance."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: as we are second group, we will be using 2 as our random state seed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Simplemente dividiremos los datos en un conjunto de train para entrenar y ajustar hiper-parámetros, y un conjunto de test en el que evaluaremos las distintas posibilidades \n",
    "que se probarán en la práctica. Hay que recordar que En problemas de clasificación \n",
    "desbalanceados hay que usar particiones estratificadas y métricas adecuadas \n",
    "(balanced_accuracy, f1, matriz de confusión). También es conveniente que los \n",
    "métodos de construcción de modelos traten el desbalanceo, usando por ejemplo \n",
    "el parámetro class_weight=”balanced”</mark>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train Test Split using Stratified K-Fold \"\"\"\n",
    "\n",
    "# Make a copy of the data (we will re-split the data later to ensure that the data is not contaminated)\n",
    "datos_copy = datos.copy()\n",
    "\n",
    "# Define the number of folds for stratified k-fold\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over the stratified k-fold splits\n",
    "for train_index, test_index in stratified_kfold.split(datos_copy, datos_copy['Attrition']):\n",
    "    # Split the data into training and test sets using the current split indices\n",
    "    train_set = datos_copy.iloc[train_index]\n",
    "    test_set = datos_copy.iloc[test_index]\n",
    "    \n",
    "    # Extract the features (X) and target (y) from the training and test sets\n",
    "    X_train = train_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
    "    y_train = train_set['Attrition']  # Extract the 'Attrition' column as the target\n",
    "    \n",
    "    X_test = test_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
    "    y_test = test_set['Attrition']  # Extract the 'Attrition' column as the target\n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the train-test division correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of X_train, y_train, X_test, y_test\n",
    "print(\"--------------------\\n\")\n",
    "print(f\"{X_train.head()}\", f\"{y_train.head()}\", f\"{X_test.head()}\", f\"{y_test.head()}\", sep=\"\\n--------------------\\n\")\n",
    "print(\"--------------------\\n\")\n",
    "\n",
    "print(f\"{X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Check is division summatory is correct\n",
    "if X_train.shape[0] + X_test.shape[0] == datos_copy.shape[0]:\n",
    "    print(\n",
    "        f\"\\nThe train test division is correct: {X_train.shape[0]} + {X_test.shape[0]} = {datos_copy.shape[0]}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nERROR: The train test division is incorrect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the train-test division correctness by comparing the class distribution in the original dataset and the train and test sets.\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(\"Original dataset class distribution:\\n\", datos_copy['Attrition'].value_counts(normalize=True))\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(\"Train set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(\"Test set class distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "print(\"\\n--------------------\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can observe, the class distribution is almost perfectly preserved in both the training and test sets and that the sum of the number of rows in train and test give us the total amount of rows in the raw dataset. This is due to the fact that the stratified k-fold algorithm does not guarantee that the class distribution is exactly the same in each fold, but rather that it is similar.\n",
    "\n",
    "Also, we can notice how the distribution of the classes is very similar in both the training and test sets, which is a good sign."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Dataset and problem description"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are given contains the following atributes information:\n",
    "\n",
    "0. **hrs**: The number of hours worked by the employee (float64)\n",
    "1. **absences**: The number of absences taken by the employee (float64)\n",
    "2. **JobInvolvement**: The level of involvement the employee has in their job (float64)\n",
    "3. **PerformanceRating**: The employee's performance rating (float64)\n",
    "4. **EnvironmentSatisfaction**: The level of satisfaction the employee has with their work environment (float64)\n",
    "5. **JobSatisfaction**: The level of satisfaction the employee has with their job (float64)\n",
    "6. **WorkLifeBalance**: The balance between work and personal life for the employee (float64)\n",
    "7. **Age**: The age of the employee (float64)\n",
    "8. **Attrition**: Whether the employee has left the company or not (object) -> **Target variable**\n",
    "9. **BusinessTravel**: The frequency of the employee's business travel (object)\n",
    "10. **Department**: The department the employee works in (object)\n",
    "11. **DistanceFromHome**: The distance from the employee's home to their workplace (float64)\n",
    "12. **Education**: The highest level of education attained by the employee (int64)\n",
    "13. **EducationField**: The field of study the employee specialized in (object)\n",
    "14. **EmployeeCount**: The number of employees in the company (float64)\n",
    "15. **EmployeeID**: A unique identifier for each employee (int64)\n",
    "16. **Gender**: The gender of the employee (object)\n",
    "17. **JobLevel**: The employee's job level in the company hierarchy (float64)\n",
    "18. **JobRole**: The specific role the employee has in their department (object)\n",
    "19. **MaritalStatus**: The employee's marital status (object)\n",
    "20. **MonthlyIncome**: The employee's monthly income (float64)\n",
    "21. **NumCompaniesWorked**: The number of companies the employee has worked for before joining the current company (float64)\n",
    "22. **Over18**: Whether the employee is over 18 years old (presumably all employees are) (object)\n",
    "23. **PercentSalaryHike**: The percentage of salary increase the employee received in their last salary hike (float64)\n",
    "24. **StandardHours**: The standard number of working hours in the company (float64)\n",
    "25. **StockOptionLevel**: The level of stock option the employee has (float64)\n",
    "26. **TotalWorkingYears**: The total number of years the employee has worked (float64)\n",
    "28. **TrainingTimesLastYear**: The number of times the employee received training in the last year (float64)\n",
    "29. **YearsAtCompany**: The number of years the employee has been with the company (float64)\n",
    "30. **YearsSinceLastPromotion**: The number of years since the employee's last promotion (float64)\n",
    "31. **YearsWithCurrManager**: The number of years the employee has been with their current manager (float64)\n",
    "\n",
    "**Note**: the values in between parenthesis correspond to the value type of each column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_atributos  = len(datos.keys())\n",
    "print(\"Se poseen\", num_atributos, \"atributos.\")\n",
    "num_instances = len(datos)\n",
    "print(\"Se poseen\", num_instances, \"instancias.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We divide the data into sting and number columns\n",
    "X_train_str = X_train.select_dtypes(include=object)\n",
    "X_train_num = X_train.select_dtypes(exclude=object)\n",
    "print(X_train_num.head())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. Dataset visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Histogram for visualization of the numerical variables \"\"\"\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "train_set.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Pie series to plot and visualize for categorical variables \"\"\"\n",
    "fig, ax = plt.subplots(4, 3, figsize=(20, 20))\n",
    "for i, col in enumerate(X_train_str):\n",
    "    train_set[col].value_counts().plot.pie(ax=ax[i//3, i%3], autopct='%1.1f%%', fontsize=12, title=col)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "## 3.2. Missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist, we check the number the total number of missing values in the dataset in order to know if we have to clean the dataset or not.\n",
    "\n",
    "We use the train_set partition (and not X_train nor y_train) as it contains both the target variable and the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_set.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Plot in a barplot the percentage of missing values in each column \"\"\"\n",
    "import pylab\n",
    "\n",
    "data = [(col, train_set[col].isnull().sum() / len(train_set))\n",
    "        for col in train_set.columns if train_set[col].isnull().sum() > 0]\n",
    "col_names = ['column', 'percent_missing']\n",
    "missing_df = pd.DataFrame(data, columns=col_names).sort_values('percent_missing')\n",
    "pylab.rcParams['figure.figsize'] = (15, 8)\n",
    "missing_df.plot(kind='barh', x='column', y='percent_missing');\n",
    "plt.title('Percent of missing values in colummns');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.1. Missing values visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Missing values bar plot \"\"\"\n",
    "msno.bar(train_set, figsize=(20, 8), fontsize=12, color='steelblue', labels=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Missing values matrix \"\"\"\n",
    "msno.matrix(train_set, figsize=(20, 8), fontsize=12, color=(0.42, 0.1, 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Missing values dendrogram \"\"\"\n",
    "msno.dendrogram(train_set, figsize=(20, 8), fontsize=12, orientation='top')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2.2. Observations and conclusion\n",
    "\n",
    "- Many variables have a significant number of missing values, ranging from 588 to over 771 missing values, which means that having 4410 rows in the dataset, we have a significant number of missing values ranging from 13.3% to 17.5% of the total number of rows in the dataset, which is significant.\n",
    "  \n",
    "  These variables include: 'hrs', 'absences', 'JobInvolvement', 'PerformanceRating', 'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age', 'BusinessTravel', 'Department', 'DistanceFromHome', 'Education', 'EmployeeCount', 'Gender', 'JobLevel', 'JobRole', 'MaritalStatus', 'MonthlyIncome', 'NumCompaniesWorked', 'Over18', 'PercentSalaryHike', 'StandardHours', 'StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear', 'YearsAtCompany', and 'YearsSinceLastPromotion'.\n",
    "\n",
    "- Some variables have no missing values, such as 'Attrition' (as it is the target variable), 'EducationField', and 'YearsWithCurrManager'.\n",
    "\n",
    "It's important to note that missing values can have an impact on the quality and reliability of the data and may require appropriate handling techniques, such as imputation or deletion, depending on the specific analysis or modeling objectives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Outliers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detecting outliers in a dataset before training a model is crucial because outliers can significantly affect the performance and accuracy of the model. Outliers are data points that deviate significantly from the rest of the dataset and can cause the model to learn incorrect patterns and relationships. When outliers are present in the data, they can also increase the variance of the model, which can result in overfitting. Overfitting occurs when the model fits too closely to the training data, leading to poor generalization to new data. Therefore, it is important to detect and handle outliers properly to ensure the model's accuracy and robustness."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** outliers are only useful when the attributes are not categorical, as they are not useful for classification problems. Therefore, only the numerical attributes will be considered in this section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1. Outliers visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3.1.1. Boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Box plot to detect outliers \"\"\"\n",
    "fig, ax = plt.subplots(figsize=(20, 10))\n",
    "sns.boxplot(data=X_train_num, orient='h', palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1.2. Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Histograms to detect outliers \"\"\"\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "train_set.hist(ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.1.3. Skewness and kurtosis\n",
    "Skewness and kurtosis are commonly used to measure the shape of a distribution. Skewness measures the degree of asymmetry in the distribution, while kurtosis measures the degree of flatness in the distribution compared to a normal distribution.\n",
    "We will look for observations that are far from the central tendency of the distribution and may indicate the presence of extreme values or data points that do not fit the pattern of the majority of the data (which as expected, happens to be the case in this dataset)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Skewness: measure of the asymmetry of the probability distribution of a real-valued random variable about its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Skewness \"\"\"\n",
    "train_set.skew().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(X_train_num.skew(), color=\"blue\", axlabel=\"Skewness\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kurtosis: measure of whether the data are heavy-tailed or light-tailed relative to a normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Kurtosis \"\"\"\n",
    "train_set.kurt().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(X_train_num.kurt(), color=\"r\", axlabel=\"Kurtosis\", norm_hist=False, kde=True, rug=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4. Correlation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are getting information about the correlation of the variables between them. This information is valuable in order to make good decisions when deleting redundant attributes. Also note we are getting information about the correlation between each attribute and the solution variable. This allows us to know the most relevant attributes, making the best decisions when creating the different models.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Correlation \"\"\"\n",
    "correlation = abs(train_set.corr())\n",
    "print(correlation.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Correlation for both numerical and categorical variables - target variable\"\"\"\n",
    "# Correlation with the target variable\n",
    "from pandas import factorize\n",
    "\n",
    "labels, uniques = factorize(train_set['Attrition'])\n",
    "train_set['Attrition'] = labels\n",
    "abs(train_set.corr()['Attrition']).sort_values(ascending=False)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining the correlation matrix formatted into our own data structure\n",
    "This is done for the sake of simplicity and to be able to visualize the correlation matrix in a more intuitive way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_dict = {}\n",
    "\n",
    "# Export the data as a list of lists\n",
    "list_correlation = correlation.values.tolist()\n",
    "\n",
    "\n",
    "# Now lets insert the each list as the value of a dictionary with the column name as the key\n",
    "for i, col in enumerate(correlation.columns):\n",
    "    correlation_dict[col] = list_correlation[i]\n",
    "    \n",
    "# Plotting the dictionary column by column sepparated by \\n\n",
    "print( \"\\n\".join(\"{}\\t{}\".format(k, v) for k, v in correlation_dict.items()) )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1. Correlation visualization\n",
    "\n",
    "## 3.5. Balance\n",
    "\n",
    "During this section, we will analyze the representation of each class in the initial train and test partitions to determine if rebalancing is necessary before fitting the models. \n",
    "\n",
    "\n",
    "\n",
    "As shown in the results above, there is a difference in the representation of the two classes, with 'No' being represented in 83% of the data and 'Yes' in 16%. This imbalance could have negative repercussions on model performance if not addressed properly. Therefore, we have decided to use the class_weight='balanced' parameter to give more weight to the errors of the minority class ('No') and less weight to the less represented class ('Yes')."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.1.1. Correlation heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Seaborn correlation heatmap \"\"\"\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20, 20))\n",
    "\n",
    "plt.title(\"Correlation Heatmap\", fontsize=20)\n",
    "sns.heatmap(\n",
    "    correlation,\n",
    "    square=True,\n",
    "    annot=True,\n",
    "    cmap=\"coolwarm\",\n",
    "    fmt=\".2f\",\n",
    "    linewidths=0.5,\n",
    "    ax=ax,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Train-Test division \n",
    "\n",
    "\n",
    "**Note**: This division was already done before in *3.0. Dataset preparation*. We overwrite it to start from a clean state so there are no possible data contamination derived from the EDA process. Thus, no further explaination is needed.\n",
    "\n",
    "<mark>En esta práctica la evaluación será más sencilla que en la primera. Simplemente \n",
    "dividiremos los datos en un conjunto de train para entrenar y ajustar hiper-\n",
    "parámetros, y un conjunto de test en el que evaluaremos las distintas posibilidades \n",
    "que se probarán en la práctica. Hay que recordar que En problemas de clasificación \n",
    "desbalanceados hay que usar particiones estratificadas y métricas adecuadas \n",
    "(balanced_accuracy, f1, matriz de confusión). También es conveniente que los \n",
    "métodos de construcción de modelos traten el desbalanceo, usando por ejemplo \n",
    "el parámetro class_weight=”balanced”.</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Stratified K-Fold Train-Test split\n",
    "To ensure a fair and unbiased evaluation of our model's performance, we will be using stratified k-fold for dividing our data into training and test sets. Stratified k-fold is a commonly used technique in machine learning that ensures that the distribution of classes in the training and test sets is similar, thus reducing the risk of introducing bias into our model's performance evaluation.\n",
    "\n",
    "By using stratified k-fold, we can ensure that each fold of the data used for training and testing our model contains a representative sample of all the classes in the dataset. This helps to account for any potential class imbalance in the data, ensuring that our model is trained and tested on a diverse set of data, leading to a more reliable evaluation of its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Train Test Split using Stratified K-Fold \"\"\"\n",
    "\n",
    "# Make a copy of the data (we will re-split the data later to ensure that the data is not contaminated)\n",
    "datos_copy = datos.copy()\n",
    "\n",
    "# Define the number of folds for stratified k-fold\n",
    "n_splits = 5\n",
    "\n",
    "# Initialize the StratifiedKFold object\n",
    "stratified_kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Iterate over the stratified k-fold splits\n",
    "for train_index, test_index in stratified_kfold.split(datos_copy, datos_copy['Attrition']):\n",
    "    # Split the data into training and test sets using the current split indices\n",
    "    train_set = datos_copy.iloc[train_index]\n",
    "    test_set = datos_copy.iloc[test_index]\n",
    "    \n",
    "    # Extract the features (X) and target (y) from the training and test sets\n",
    "    X_train = train_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
    "    y_train = train_set['Attrition']  # Extract the 'Attrition' column as the target\n",
    "    \n",
    "    X_test = test_set.drop('Attrition', axis=1)  # Drop the 'Attrition' column to get the features\n",
    "    y_test = test_set['Attrition']  # Extract the 'Attrition' column as the target\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the head of X_train, y_train, X_test, y_test\n",
    "print(\"--------------------\\n\")\n",
    "print(f\"{X_train.head()}\", f\"{y_train.head()}\", f\"{X_test.head()}\", f\"{y_test.head()}\", sep=\"\\n--------------------\\n\")\n",
    "print(\"--------------------\\n\")\n",
    "\n",
    "print(f\"{X_train.shape}, {y_train.shape}, {X_test.shape}, {y_test.shape}\")\n",
    "\n",
    "# Check is division summatory is correct\n",
    "if X_train.shape[0] + X_test.shape[0] == datos_copy.shape[0]:\n",
    "    print(\n",
    "        f\"\\nThe train test division is correct: {X_train.shape[0]} + {X_test.shape[0]} = {datos_copy.shape[0]}\"\n",
    "    )\n",
    "else:\n",
    "    print(\"\\nERROR: The train test division is incorrect\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the train-test division correctness by comparing the class distribution in the original dataset and the train and test sets.\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(\"Original dataset class distribution:\\n\", datos_copy['Attrition'].value_counts(normalize=True))\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(\"Train set class distribution:\\n\", y_train.value_counts(normalize=True))\n",
    "print(\"\\n--------------------\\n\")\n",
    "print(\"Test set class distribution:\\n\", y_test.value_counts(normalize=True))\n",
    "print(\"\\n--------------------\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Train-Test Error metrics\n",
    "\n",
    "For classification problems, the most common metrics used to evaluate the performance of a model are accuracy, precision, recall, and F1 score. However, these metrics are not always the best choice for evaluating the performance of a model, especially when the dataset is imbalanced.<br>In this case, we will be using the following metrics to evaluate the performance of our models: **balanced accuracy, F1 score, and confusion matrix**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Print model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(name, model, score, time, test=False):\n",
    "    print(\"---------------------------------------------------\")\n",
    "    print(f\"{name} best model is:\\n\\n{model}\")\n",
    "    print(\"\\nParameters:\", model.best_params_)\n",
    "\n",
    "    print(\n",
    "        f\"\\nPerformance: NMAE (val): {score[0]}\",\n",
    "        f\"RMSE train: {score[1]}\",\n",
    "        f\"MAE train: {score[2]}\",\n",
    "        f\"RMSE train in validation: {score[3]}\",\n",
    "        f\"MAE train in validation: {score[4]}\",\n",
    "        f\"RMSE test in validation: {score[5]}\",\n",
    "        f\"MAE test in validation: {score[6]}\",\n",
    "        sep=\" | \",\n",
    "    )\n",
    "    \n",
    "    if test:\n",
    "        print(\n",
    "            f\"RMSE test: {score[7]}\",\n",
    "            f\"MAE test: {score[8]}\",\n",
    "            sep=\" | \",\n",
    "        )\n",
    "        \n",
    "\n",
    "    print(f\"Execution time: {time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Validation splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation_splits(model, X_train):\n",
    "    dict_folds = {}\n",
    "    \n",
    "    for n_splits, (train_index, test_index) in enumerate(model.cv.split(X_train)):\n",
    "        index = \"F\" + str(n_splits + 1)\n",
    "        train_index_formatted = []\n",
    "        test_index_formatted = []\n",
    "\n",
    "        for i in range(len(train_index)):\n",
    "            train_index_formatted.append(\"V\" + str(int(train_index[i] + 1)))\n",
    "\n",
    "        for i in range(len(test_index)):\n",
    "            test_index_formatted.append(\"V\" + str(int(test_index[i] + 1)))\n",
    "\n",
    "        dict_folds[index] = [train_index_formatted, test_index_formatted]\n",
    "        \n",
    "    return dict_folds"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Dataset preparation\n",
    "Here, we will tre"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Model construction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>(1.3 puntos) Construcción de modelos: para esta práctica usaremos\n",
    "LogisticRegression como método base (sin ajustar hiper-parámetros) y Boosting\n",
    "como método avanzado (ajustando hiper-parámetros), a elegir. Es importante \n",
    "realizar los preprocesos que los datos necesiten, usando preferentemente \n",
    "pipelines. Como método de boosting, se puede elegir uno de entre los métodos de \n",
    "boosting disponibles en scikit-learn. Si además se usa uno de entre las librerías \n",
    "externas xgboost, lightgbm o catboost, se pueden sacar +0.35 puntos adicionale</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>(0.8 puntos) Usando algún método de selección de atributos de tipo filter\n",
    "(SelectKBest) de entre los disponibles en sklearn (f_classif, \n",
    "mutual_info_classif o chi2), comprobad si se pueden mejorar los resultados del \n",
    "apartado anterior y extraer conclusiones sobre qué atributos son más importantes, \n",
    "al menos de acuerdo a estos métodos</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Logistic Regression\n",
    "Logistic regression with no hyperparameter tuning. It will be used as a baseline for the rest of the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1. Logistic Regression - Predefined parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1.1. Logistic Regression - Predefined parameters - No attribute selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputación\n",
    "Se conoce como imputación al proceso de tratamiento de los valores faltantes (missing values\n",
    "o NA’s) en las instancias del conjunto de datos. Este tipo de proceso es importante en algunos\n",
    "métodos como KNN y en los árboles de Sklearn, ya que estos métodos no pueden trabajar con\n",
    "estos tipos d e datos. Para tratar estos datos, podemos seguir los siguientes métodos directos:\n",
    "➢ Eliminar las instancias (filas) que tengan al menos 1 NA\n",
    "➢ Eliminar los atributos (columnas) que tengan al menos 1 NA\n",
    "DiegoC_UC3M en Wuolah Aprendizaje automático\n",
    "Tema 6\n",
    "3\n",
    "Aunque ambos métodos solucionan el problema, pueden provocar la perdida de información;\n",
    "por lo que existen otro métodos automáticos como son:\n",
    "➢ Univariante: para imputar el valor NA’s de un atributo, se usan sólo valores de ese atributo\n",
    "o En sklearn → sklearn.impute.SimpleImputer\n",
    "➢ Multivariante: para imputar valores NA’s de un atributo, se pueden usar valores de todos los\n",
    "atributos. En este tipo de método encontramos dos variantes:\n",
    "o Basado en modelos → sklearn.impute.IterativeImputer\n",
    "o Basado en KNN → skelarn.impute.KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Pipeline for Logistic Regression\n",
    "# For imputing missing values we have various options:\n",
    "# SimpleImputer, IterativeImputer, KNNImputer, MICEImputer, etc.\n",
    "\n",
    "# We will use IterativeImputer as MICE would require a lot of time to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Logistic Regression with the default parameters \"\"\"\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "np.random.seed(2)\n",
    "\n",
    "# ! ValueError: could not convert string to float\n",
    "# Use one hot encoding for categorical variables\n",
    "\n",
    "pipeline_lr = Pipeline(\n",
    "    [\n",
    "        (\"imputer\", IterativeImputer()),\n",
    "        # (\"scaler\", StandardScaler()),\n",
    "        (\"model\", LogisticRegression()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid_lr = {\n",
    "    \"model__penalty\": [\"l2\"],\n",
    "    \"model__C\": [1.0],\n",
    "    \"model__fit_intercept\": [True],\n",
    "    \"model__solver\": [\"lbfgs\"],\n",
    "    \"model__max_iter\": [100],\n",
    "    \"model__multi_class\": [\"auto\"],\n",
    "}\n",
    "\n",
    "model_lr = GridSearchCV(\n",
    "    pipeline_lr,\n",
    "    param_grid_lr,\n",
    "    cv=StratifiedKFold(n_splits=5, shuffle=True, random_state=2),\n",
    "    scoring=\"balanced_accuracy\",\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model_lr.fit(X_train, y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "time_lr = end_time - start_time\n",
    "\n",
    "print_results(\"Logistic Regression\", model_lr, model_lr.cv_results_[\"mean_test_score\"], time_lr)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1.2. Logistic Regression - Predefined parameters - Attribute selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Boosting\n",
    "With <mark>(?)</mark> and without hyperparameter tuning."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Como método de boosting, se puede elegir uno de entre los métodos de \n",
    "boosting disponibles en scikit-learn. Si además se usa uno de entre las librerías \n",
    "externas xgboost, lightgbm o catboost, se pueden sacar +0.35 puntos adicionales.</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Boosting - Predefined parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librerías necesarias\n",
    "import numpy as np\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "import time\n",
    "\n",
    "np.random.seed(10)\n",
    "budget = 10\n",
    "n_splits = 5\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    [\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"selector\", SelectKBest(chi2)),\n",
    "        (\"model\", GradientBoostingClassifier()),\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"selector__k\": [10],\n",
    "    \"model__n_estimators\": [100],\n",
    "    \"model__learning_rate\": [0.1],\n",
    "    \"model__max_depth\": [3],\n",
    "    \"model__min_samples_split\": [2],\n",
    "    \"model__min_samples_leaf\": [1],\n",
    "    \"model__subsample\": [1.0],\n",
    "    \"model__random_state\": [10],\n",
    "}\n",
    "\n",
    "\n",
    "model = RandomizedSearchCV(\n",
    "    pipeline,\n",
    "    param_distributions=param_grid,\n",
    "    scoring=\"neg_mean_absolute_error\",\n",
    "    cv=TimeSeriesSplit(n_splits=n_splits),\n",
    "    n_iter=budget,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "model.fit(X=X_train, y=y_train)\n",
    "end_time = time.time()\n",
    "\n",
    "total_time = end_time - start_time\n",
    "\n",
    "score = train_and_test(\n",
    "    model.best_estimator_, model.best_score_, X_train, y_train, X_test, y_test\n",
    ")\n",
    "\n",
    "results[\"SVM_select\"] = score\n",
    "times[\"SVM_select\"] = total_time\n",
    "\n",
    "print_results(\"SVM SELECTED PARAMETERS\", model, model.best_score_, score, total_time)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.1. Boosting - Predefined parameters - No attribute selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.1.2. Boosting - Predefined parameters - Attribute selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Boosting - Selected parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2.1. Boosting - Selected parameters - No attribute selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.2.2.2. Boosting - Selected parameters - Attribute selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<mark>Código en un notebook. Es necesario que a lo largo de la práctica se vayan extrayendo \n",
    "conclusiones, y al final de la práctica, hay que hacer un resumen de todos los resultados \n",
    "obtenidos, usando tablas y/o gráficos.\n",
    "● El archivo conteniendo el mejor modelo obtenido (llamado «modelo_final.pkl»).</mark>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Conclusions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Model evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1. Best Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1.1. Best Model Prediction - Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2. Selected Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2.1. Selected Model Prediction and Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3. Selected Model Export"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 9. Final Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During this project, we have had the opportunity to gain a deeper understanding of the model selection process. We began with exploratory data analysis (EDA), which helped us to improve our understanding and management of the data. We found this to be an extremely useful tool throughout the entire project. We believe that this part of the project should be evaluated with greater emphasis, as it is the foundation upon which all of our decisions were based.\n",
    "\n",
    "Next, we created and trained all of our models, gaining experience in the use of pipelines and a deeper understanding of the importance of hyperparameters. Finally, we analyzed the different results provided by each model, gaining a better understanding of their respective advantages and disadvantages in terms of scoring and time.\n",
    "\n",
    "We believe that this project is an excellent complement to the main lessons, as it provides a deeper understanding of the subject matter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# X. Output the Jupyter Notebook as an HTML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Export the notebook to HTML\n",
    "os.system(\"jupyter nbconvert --to html model.ipynb --output ../data/html/model.html\")\n",
    "print(\"Notebook exported to HTML\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_practica_2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
